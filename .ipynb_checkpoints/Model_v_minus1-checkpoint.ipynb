{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f11483-d086-4a21-8d8b-ed6f808e3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show keras tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ecf9bc6-431e-4ca7-8cd8-b68f7f0eb6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 13:43:05.351121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738138385.534304    4409 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738138385.589286    4409 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 13:43:05.997155: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to /home/dhruv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/dhruv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from google.cloud import vision\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import spacy\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0623afa4-ea84-447a-b8f4-590e13793be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path, output_folder):\n",
    "    \"\"\"Convert a PDF to images, one image per page.\"\"\"\n",
    "    images = convert_from_path(pdf_path)\n",
    "    image_paths = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image_path = f\"{output_folder}/page_{i + 1}.jpg\"\n",
    "        image.save(image_path, \"JPEG\")\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763d2831-32dc-45e1-8913-f2d080aacb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_images(image_paths):\n",
    "    \"\"\"Extract text from a list of image paths using Google Cloud Vision.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    all_text = \"\"\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "        \n",
    "        image = vision.Image(content=content)\n",
    "        response = client.document_text_detection(image=image)\n",
    "\n",
    "        if response.error.message:\n",
    "            raise Exception(f\"Error processing {image_path}: {response.error.message}\")\n",
    "\n",
    "        all_text += response.full_text_annotation.text + \"\\n\"\n",
    "\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29b4120-2e91-489f-9c00-2577540d1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_without_buckets(pdf_path, output_folder):\n",
    "    \"\"\"Process a PDF file without using Google Cloud Storage.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    print(\"Converting PDF to images...\")\n",
    "    image_paths = pdf_to_images(pdf_path, output_folder)\n",
    "\n",
    "    print(\"Extracting text from images...\")\n",
    "    extracted_text = extract_text_from_images(image_paths)\n",
    "\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4ebbef-dc08-48dc-95c4-c633446a03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by removing stopwords, punctuation, and lowercasing.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6713b5a4-6c2b-428a-98af-526d3442386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_score(text1, text2):\n",
    "    \"\"\"Calculate the similarity score between two texts using SBERT.\"\"\"\n",
    "    sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    embeddings1 = sbert_model.encode(text1, convert_to_tensor=True)\n",
    "    embeddings2 = sbert_model.encode(text2, convert_to_tensor=True)\n",
    "    cosine_similarity = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f0a40d-f80c-4fd3-ba62-38c1042f8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(student_pdf_path, teacher_answer_path, output_folder):\n",
    "    # Extract text from student's PDF\n",
    "    print(\"Processing student's PDF...\")\n",
    "    student_text = process_pdf_without_buckets(student_pdf_path, output_folder)\n",
    "    \n",
    "    # If teacher's answer is a PDF, extract text; otherwise, read as text\n",
    "    if teacher_answer_path.endswith('.pdf'):\n",
    "        print(\"Processing teacher's PDF...\")\n",
    "        teacher_text = process_pdf_without_buckets(teacher_answer_path, output_folder)\n",
    "    else:\n",
    "        with open(teacher_answer_path, 'r') as file:\n",
    "            teacher_text = file.read()\n",
    "    \n",
    "    # Preprocess both texts\n",
    "    print(\"Preprocessing texts...\")\n",
    "    student_text_processed = preprocess_text(student_text)\n",
    "    teacher_text_processed = preprocess_text(teacher_text)\n",
    "    \n",
    "    # Calculate similarity score\n",
    "    print(\"Calculating similarity score...\")\n",
    "    similarity_score = get_similarity_score(student_text_processed, teacher_text_processed)\n",
    "    \n",
    "    # Assign marks based on similarity score (example: out of 10)\n",
    "    marks = round(similarity_score * 10, 2)\n",
    "    \n",
    "    print(f\"Similarity Score: {similarity_score}\")\n",
    "    print(f\"Marks Awarded: {marks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8391aa1-2281-4a59-a9e5-c2961c98b889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's PDF...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Preprocessing texts...\n",
      "Calculating similarity score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.7783663272857666\n",
      "Marks Awarded: 7.78\n"
     ]
    }
   ],
   "source": [
    "student_pdf_path = \"/home/dhruv/Desktop/CloudOCR/myAnswer.pdf\"\n",
    "teacher_answer_path = \"/home/dhruv/Desktop/CloudOCR/teacher_answer.txt\"\n",
    "output_folder = \"output_images\"\n",
    "\n",
    "main(student_pdf_path, teacher_answer_path, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ed8a8-ae41-42c2-8372-2890eba41ef0",
   "metadata": {},
   "source": [
    "## Entire Paper stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046dc219-28bf-4f7d-92d5-8b2983010168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "from google.cloud import vision\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf997f6-4ed5-472c-b192-dd0443660d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_questions_from_pdf(pdf_path):\n",
    "    \"\"\"Extract questions and their details from PDF with improved parsing.\"\"\"\n",
    "    \n",
    "    def pdf_to_images(pdf_path, output_folder='temp_images'):\n",
    "        \"\"\"Convert PDF to images.\"\"\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        images = convert_from_path(pdf_path)\n",
    "        image_paths = []\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            image_path = f\"{output_folder}/page_{i + 1}.jpg\"\n",
    "            image.save(image_path, \"JPEG\")\n",
    "            image_paths.append(image_path)\n",
    "            \n",
    "        return image_paths\n",
    "\n",
    "    def extract_text_from_images(image_paths):\n",
    "        \"\"\"Extract text using Google Cloud Vision.\"\"\"\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "        all_text = \"\"\n",
    "        \n",
    "        for image_path in image_paths:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                content = image_file.read()\n",
    "            \n",
    "            image = vision.Image(content=content)\n",
    "            response = client.document_text_detection(image=image)\n",
    "            \n",
    "            if response.error.message:\n",
    "                raise Exception(f\"Error processing {image_path}: {response.error.message}\")\n",
    "                \n",
    "            all_text += response.full_text_annotation.text + \"\\n\"\n",
    "            \n",
    "        return all_text\n",
    "\n",
    "    def parse_questions(text):\n",
    "        \"\"\"Parse questions with multiple pattern matching attempts.\"\"\"\n",
    "        # Print the extracted text for debugging\n",
    "        print(\"\\nExtracted text from PDF:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(text)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Try different question patterns\n",
    "        patterns = [\n",
    "            r'Q\\.?\\s*(\\d+)\\.(.*?)(?=Q\\.?\\s*\\d+\\.|$)',  # Q. 1. or Q1.\n",
    "            r'Question\\s*(\\d+)[.:]?(.*?)(?=Question\\s*\\d+|$)',  # Question 1:\n",
    "            r'(\\d+)\\.(.*?)(?=\\d+\\.|$)',  # 1.\n",
    "            r'$$(\\d+)$$(.*?)(?=$$\\d+$$|$)'  # (1)\n",
    "        ]\n",
    "        \n",
    "        marks_patterns = [\n",
    "            r'$$(\\d+)\\s*marks?$$',  # (5 marks) or (5 mark)\n",
    "            r'(\\d+)\\s*marks?',      # 5 marks\n",
    "            r'$$(\\d+)\\s*marks?$$'   # [5 marks]\n",
    "        ]\n",
    "        \n",
    "        questions = {}\n",
    "        \n",
    "        # Try each pattern until we find questions\n",
    "        for pattern in patterns:\n",
    "            matches = list(re.finditer(pattern, text, re.DOTALL | re.IGNORECASE))\n",
    "            if matches:\n",
    "                print(f\"\\nFound questions using pattern: {pattern}\")\n",
    "                for match in matches:\n",
    "                    q_num = match.group(1)\n",
    "                    q_text = match.group(2).strip()\n",
    "                    \n",
    "                    # Try to extract marks\n",
    "                    marks = 0\n",
    "                    for marks_pattern in marks_patterns:\n",
    "                        marks_match = re.search(marks_pattern, q_text, re.IGNORECASE)\n",
    "                        if marks_match:\n",
    "                            marks = int(marks_match.group(1))\n",
    "                            # Remove marks pattern from question text\n",
    "                            q_text = re.sub(marks_pattern, '', q_text, flags=re.IGNORECASE).strip()\n",
    "                            break\n",
    "                    \n",
    "                    questions[q_num] = {\n",
    "                        'question_text': q_text,\n",
    "                        'marks': marks\n",
    "                    }\n",
    "                    print(f\"\\nFound Question {q_num}:\")\n",
    "                    print(f\"Text: {q_text[:100]}...\")  # Print first 100 chars\n",
    "                    print(f\"Marks: {marks}\")\n",
    "                \n",
    "                if questions:  # If we found any questions, stop trying patterns\n",
    "                    break\n",
    "        \n",
    "        return questions\n",
    "\n",
    "    try:\n",
    "        # Process PDF\n",
    "        print(\"Converting PDF to images...\")\n",
    "        image_paths = pdf_to_images(pdf_path)\n",
    "        \n",
    "        print(\"Extracting text from images...\")\n",
    "        extracted_text = extract_text_from_images(image_paths)\n",
    "        \n",
    "        print(\"Parsing questions...\")\n",
    "        questions = parse_questions(extracted_text)\n",
    "        \n",
    "        # Cleanup temporary images\n",
    "        for image_path in image_paths:\n",
    "            os.remove(image_path)\n",
    "        os.rmdir('temp_images')\n",
    "        \n",
    "        if not questions:\n",
    "            print(\"No questions were found in the text.\")\n",
    "            return None\n",
    "            \n",
    "        return questions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1a92756-0462-4ca2-a4df-56dabe23a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionPaper:\n",
    "    def __init__(self, paper_id):\n",
    "        self.paper_id = paper_id\n",
    "        self.questions = {}\n",
    "        self.total_marks = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_text_from_pdf(pdf_path):\n",
    "        \"\"\"Extract text from PDF using Google Cloud Vision.\"\"\"\n",
    "        try:\n",
    "            # Convert PDF to images\n",
    "            print(\"Converting PDF to images...\")\n",
    "            images = convert_from_path(pdf_path)\n",
    "            \n",
    "            # Setup Google Cloud Vision\n",
    "            client = vision.ImageAnnotatorClient()\n",
    "            extracted_text = \"\"\n",
    "            \n",
    "            print(\"Extracting text from images...\")\n",
    "            for i, image in enumerate(images):\n",
    "                # Save image temporarily\n",
    "                image_path = f\"temp_page_{i}.jpg\"\n",
    "                image.save(image_path, \"JPEG\")\n",
    "                \n",
    "                # Extract text from image\n",
    "                with open(image_path, \"rb\") as image_file:\n",
    "                    content = image_file.read()\n",
    "                image = vision.Image(content=content)\n",
    "                response = client.document_text_detection(image=image)\n",
    "                extracted_text += response.full_text_annotation.text + \"\\n\"\n",
    "                \n",
    "                # Clean up temp image\n",
    "                os.remove(image_path)\n",
    "            \n",
    "            return extracted_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in text extraction: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_questions(text):\n",
    "        \"\"\"Parse questions from extracted text.\"\"\"\n",
    "        # Print the extracted text for debugging\n",
    "        print(\"\\nExtracted text:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(text)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        questions = {}\n",
    "        \n",
    "        # Pattern to match questions with parts\n",
    "        pattern = r'Q\\.?\\s*(\\d+)([AB]?)\\.?\\s*([^Q]*)(?=Q\\.|$)'\n",
    "        matches = re.finditer(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        \n",
    "        for match in matches:\n",
    "            q_num = match.group(1)\n",
    "            q_part = match.group(2) if match.group(2) else ''\n",
    "            q_text = match.group(3).strip()\n",
    "            \n",
    "            # Extract marks\n",
    "            marks_match = re.search(r'(?:Max\\.\\s*Marks\\s*(\\d+))|(\\d+)\\s*marks?', q_text, re.IGNORECASE)\n",
    "            marks = int(marks_match.group(1) or marks_match.group(2)) if marks_match else 5\n",
    "            \n",
    "            # Clean question text\n",
    "            q_text = re.sub(r'(?:Max\\.\\s*Marks\\s*\\d+)|(?:\\d+\\s*marks?)', '', q_text, re.IGNORECASE)\n",
    "            q_text = re.sub(r'OR', '', q_text)\n",
    "            q_text = ' '.join(q_text.split())  # Clean up whitespace\n",
    "            \n",
    "            question_id = f\"{q_num}{q_part}\"\n",
    "            questions[question_id] = {\n",
    "                'text': q_text,\n",
    "                'marks': marks\n",
    "            }\n",
    "            \n",
    "            # Print parsed question for debugging\n",
    "            print(f\"\\nParsed Q{question_id}:\")\n",
    "            print(f\"Text: {q_text}\")\n",
    "            print(f\"Marks: {marks}\")\n",
    "        \n",
    "        return questions\n",
    "\n",
    "    @classmethod\n",
    "    def from_pdf(cls, pdf_path, paper_id):\n",
    "        \"\"\"Create QuestionPaper instance from PDF file.\"\"\"\n",
    "        paper = cls(paper_id)\n",
    "        \n",
    "        # Extract text from PDF\n",
    "        extracted_text = cls.extract_text_from_pdf(pdf_path)\n",
    "        if not extracted_text:\n",
    "            return None\n",
    "        \n",
    "        # Parse questions\n",
    "        paper.questions = cls.parse_questions(extracted_text)\n",
    "        paper.total_marks = sum(q['marks'] for q in paper.questions.values())\n",
    "        \n",
    "        if paper.questions:\n",
    "            print(f\"\\nSuccessfully extracted {len(paper.questions)} questions\")\n",
    "            print(f\"Total marks: {paper.total_marks}\")\n",
    "        else:\n",
    "            print(\"No questions were extracted from the PDF\")\n",
    "        \n",
    "        return paper\n",
    "\n",
    "    def display_questions(self):\n",
    "        \"\"\"Display formatted questions.\"\"\"\n",
    "        print(f\"\\nQuestion Paper ID: {self.paper_id}\")\n",
    "        print(f\"Total Marks: {self.total_marks}\")\n",
    "        print(\"\\nQuestions:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for q_num, q_data in sorted(self.questions.items()):\n",
    "            print(f\"\\nQuestion {q_num}:\")\n",
    "            print(f\"Text: {q_data['text']}\")  # Changed from 'question_text' to 'text'\n",
    "            print(f\"Marks: {q_data['marks']}\")\n",
    "            if 'model_answer' in q_data:\n",
    "                print(f\"Model Answer: {q_data['model_answer']}\")\n",
    "\n",
    "    def to_dataframe(self):\n",
    "        \"\"\"Convert questions to pandas DataFrame.\"\"\"\n",
    "        questions_list = []\n",
    "        \n",
    "        for q_num, q_data in sorted(self.questions.items()):\n",
    "            row = {\n",
    "                'Question No.': f'Q{q_num}',\n",
    "                'Question': q_data['text'],  # Changed from 'question_text' to 'text'\n",
    "                'Marks': q_data['marks']\n",
    "            }\n",
    "            if 'model_answer' in q_data:\n",
    "                row['Model Answer'] = q_data['model_answer']\n",
    "            questions_list.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(questions_list)\n",
    "        return df\n",
    "\n",
    "    def get_raw_text(self):\n",
    "        \"\"\"Get raw text of all questions.\"\"\"\n",
    "        raw_text = []\n",
    "        for q_num, q_data in sorted(self.questions.items()):\n",
    "            question_text = f\"Q{q_num} {q_data['text']} Max. Marks {q_data['marks']}\"\n",
    "            raw_text.append(question_text)\n",
    "        return '\\n'.join(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b662d1bb-d688-4e49-9c74-3d1bca0bbd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Error in text extraction: Unable to get page count.\n",
      "I/O Error: Couldn't open file 'QPTEST-Crop.pdf': No such file or directory.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'display_questions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m paper \u001b[38;5;241m=\u001b[39m QuestionPaper\u001b[38;5;241m.\u001b[39mfrom_pdf(pdf_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXAM2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Display questions\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mpaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_questions\u001b[49m()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get raw text\u001b[39;00m\n\u001b[1;32m     15\u001b[0m raw_text \u001b[38;5;241m=\u001b[39m paper\u001b[38;5;241m.\u001b[39mget_raw_text()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'display_questions'"
     ]
    }
   ],
   "source": [
    "# Create from PDF\n",
    "\n",
    "pdf_path = \"QPTEST-Crop.pdf\"\n",
    "\n",
    "paper = QuestionPaper.from_pdf(pdf_path, \"EXAM2\")\n",
    "\n",
    "\n",
    "# Display questions\n",
    "\n",
    "paper.display_questions()\n",
    "\n",
    "\n",
    "# Get raw text\n",
    "\n",
    "raw_text = paper.get_raw_text()\n",
    "\n",
    "print(raw_text)\n",
    "\n",
    "\n",
    "# Get as DataFrame\n",
    "\n",
    "df = paper.to_dataframe()\n",
    "\n",
    "display(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e74a661f-b74a-45cc-a014-01ea2e1cbbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Parsing questions...\n",
      "\n",
      "Successfully extracted 1 questions.\n",
      "Extracted 1 questions from PDF\n",
      "\n",
      "Extracted Questions:\n",
      "\n",
      "Question 2:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'question_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m paper\u001b[38;5;241m.\u001b[39mquestions:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExtracted Questions:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mpaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNo questions were extracted. Please check the PDF format.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 48\u001b[0m, in \u001b[0;36mQuestionPaper.display_questions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q_num, q_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mq_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarks\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_answer\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m q_data:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question_text'"
     ]
    }
   ],
   "source": [
    "# Create question paper from PDF with debugging\n",
    "pdf_path = \"qpconvert.pdf\"\n",
    "paper = QuestionPaper.from_pdf(pdf_path, \"EXAM2023001\")\n",
    "\n",
    "# If questions were found, display them\n",
    "if paper.questions:\n",
    "    print(\"\\nExtracted Questions:\")\n",
    "    paper.display_questions()\n",
    "else:\n",
    "    print(\"\\nNo questions were extracted. Please check the PDF format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87ac11a3-ef8d-4edc-8ec8-2dc193e62574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Parsing questions...\n",
      "\n",
      "Successfully extracted 1 questions.\n",
      "\n",
      "Extracted Questions:\n",
      "\n",
      "Question Paper ID: TEST_NoC\n",
      "Total Marks: 0\n",
      "\n",
      "Questions:\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 1 (0 marks)\n",
      "a Describe how the Canny Edge Detector algorithm can be applied to an image to detect edges. Include the steps involved and discuss how this approach contributes to better image analysis. 05 OR Q1 b Explain the Hough Transform and its fundamental concepts. Consider the edge pixels detected at coordinates 1,1 and 3,3. 05 Q2 a Analyze the impact of different morphological operators used in image processing, such as dilation, erosion, opening, and closing. How do these operations impact binary images? 05 OR Q2 b Describe how different noise can be handled in image restoration. How can restoration algorithms be applied to reduce or eliminate these types of noise from an image. 05 Q3 Analyze the differences and similarities between optical flow and the motion field. 05 PLOT NO. U15, JVPD SCHEME, BHAKTIVEDANTA SWAMI MARG, VILE PARLE WEST, MUMBAI  400056. Tel. 4233500042335001 Email infodjsce.ac.in admindjsce.ac.in Website www.djsce ac in\n"
     ]
    }
   ],
   "source": [
    "# Create question paper from PDF with debugging\n",
    "pdf_path = \"QPTest-Nocrop.pdf\"\n",
    "paper = QuestionPaper.from_pdf(pdf_path, \"TEST_NoC\")\n",
    "\n",
    "# If questions were found, display them\n",
    "if paper.questions:\n",
    "    print(\"\\nExtracted Questions:\")\n",
    "    paper.display_questions()\n",
    "else:\n",
    "    print(\"\\nNo questions were extracted. Please check the PDF format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "384cbe2a-443c-4336-a9ff-2c1c05a392be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Parsing questions...\n",
      "\n",
      "Successfully extracted 1 questions.\n",
      "Extracted 1 questions from PDF\n",
      "\n",
      "Extracted Questions:\n",
      "\n",
      "Question 1:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'question_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m paper\u001b[38;5;241m.\u001b[39mquestions:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExtracted Questions:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mpaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNo questions were extracted. Please check the PDF format.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 48\u001b[0m, in \u001b[0;36mQuestionPaper.display_questions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q_num, q_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mq_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarks\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_answer\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m q_data:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question_text'"
     ]
    }
   ],
   "source": [
    "# Create question paper from PDF with debugging\n",
    "pdf_path = \"QPTest-Crop.pdf\"\n",
    "paper = QuestionPaper.from_pdf(pdf_path, \"TEST_C\")\n",
    "\n",
    "# If questions were found, display them\n",
    "if paper.questions:\n",
    "    print(\"\\nExtracted Questions:\")\n",
    "    paper.display_questions()\n",
    "else:\n",
    "    print(\"\\nNo questions were extracted. Please check the PDF format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1558bcfa-ae15-498f-b2fc-5057c9c3fd85",
   "metadata": {},
   "source": [
    "### Question organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f985d37-0635-44e5-989e-858446bcf4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_questions(text):\n",
    "    \"\"\"Preprocess and structure questions from raw text.\"\"\"\n",
    "    \n",
    "    # Pattern to match questions with parts\n",
    "    pattern = r'Q(\\d+)\\s*([ab])?\\s*(?:Question)?\\s*([^Q]*)(?=Q\\d+|$)'\n",
    "    \n",
    "    # Clean and structure questions\n",
    "    questions = []\n",
    "    matches = re.finditer(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "    for match in matches:\n",
    "        q_num = match.group(1)\n",
    "        q_part = match.group(2) if match.group(2) else ''\n",
    "        q_text = match.group(3).strip()\n",
    "        \n",
    "        # Extract marks\n",
    "        marks_match = re.search(r'Max\\.\\s*Marks\\s*(\\d+)', q_text)\n",
    "        marks = int(marks_match.group(1)) if marks_match else 5\n",
    "        \n",
    "        # Clean question text\n",
    "        q_text = re.sub(r'Max\\.\\s*Marks\\s*\\d+', '', q_text)\n",
    "        q_text = re.sub(r'OR', '', q_text)\n",
    "        q_text = q_text.strip()\n",
    "        \n",
    "        questions.append({\n",
    "            'question_number': f'Q{q_num}{q_part}',\n",
    "            'question_text': q_text,\n",
    "            'marks': marks\n",
    "        })\n",
    "    \n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac00240-72c3-478d-a54c-e8a7a3556405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structured_df(questions):\n",
    "    \"\"\"Create a structured DataFrame from processed questions.\"\"\"\n",
    "    df = pd.DataFrame(questions)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df.columns = ['Question No.', 'Question', 'Marks']\n",
    "    \n",
    "    # Calculate total marks\n",
    "    total_marks = df['Marks'].sum()\n",
    "    \n",
    "    print(f\"Total Questions: {len(df)}\")\n",
    "    print(f\"Total Marks: {total_marks}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "904337d6-3d32-4cd2-90c7-1cfa05ec5ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question Paper ID: TEST_C\n",
      "Total Marks: 0\n",
      "\n",
      "Questions:\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 1 (0 marks)\n",
      "a Question Describe how the Canny Edge Detector algorithm can be applied to an image to detect edges. Include the steps involved and discuss how this approach contributes to better image analysis. Max. Marks 05 OR Q1 b Explain the Hough Transform and its fundamental concepts. Consider the edge pixels detected at coordinates 1,1 and 3,3. 05 Q2 a Analyze the impact of different morphological operators used in image processing, such as dilation, erosion, opening, and closing. How do these operations impact binary images? 05 OR Q2 b Describe how different noise can be handled in image restoration. How can restoration algorithms be applied to reduce or eliminate these types of noise from an image. 05 Q3 Analyze the differences and similarities between optical flow and the motion field. 05\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m raw_text \u001b[38;5;241m=\u001b[39mpaper\u001b[38;5;241m.\u001b[39mdisplay_questions()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Process questions and create DataFrame\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m questions \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m create_structured_df(questions)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Display structured questions\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m, in \u001b[0;36mpreprocess_questions\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Clean and structure questions\u001b[39;00m\n\u001b[1;32m      8\u001b[0m questions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDOTALL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIGNORECASE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m matches:\n\u001b[1;32m     12\u001b[0m     q_num \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/re/__init__.py:224\u001b[0m, in \u001b[0;36mfinditer\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinditer\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return an iterator over all non-overlapping matches in the\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    string.  For each match, the iterator returns a Match object.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Your raw text\n",
    "raw_text =paper.display_questions()\n",
    "\n",
    "# Process questions and create DataFrame\n",
    "questions = preprocess_questions(raw_text)\n",
    "df = create_structured_df(questions)\n",
    "\n",
    "# Display structured questions\n",
    "print(\"\\nStructured Questions:\")\n",
    "print(\"-\" * 50)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0fb38-3466-4901-b270-ea82e0b4062c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
