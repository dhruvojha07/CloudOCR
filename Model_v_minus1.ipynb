{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f11483-d086-4a21-8d8b-ed6f808e3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show keras tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ecf9bc6-431e-4ca7-8cd8-b68f7f0eb6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 13:43:05.351121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738138385.534304    4409 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738138385.589286    4409 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 13:43:05.997155: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to /home/dhruv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/dhruv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from google.cloud import vision\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import spacy\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0623afa4-ea84-447a-b8f4-590e13793be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path, output_folder):\n",
    "    \"\"\"Convert a PDF to images, one image per page.\"\"\"\n",
    "    images = convert_from_path(pdf_path)\n",
    "    image_paths = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image_path = f\"{output_folder}/page_{i + 1}.jpg\"\n",
    "        image.save(image_path, \"JPEG\")\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763d2831-32dc-45e1-8913-f2d080aacb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_images(image_paths):\n",
    "    \"\"\"Extract text from a list of image paths using Google Cloud Vision.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    all_text = \"\"\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "        \n",
    "        image = vision.Image(content=content)\n",
    "        response = client.document_text_detection(image=image)\n",
    "\n",
    "        if response.error.message:\n",
    "            raise Exception(f\"Error processing {image_path}: {response.error.message}\")\n",
    "\n",
    "        all_text += response.full_text_annotation.text + \"\\n\"\n",
    "\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29b4120-2e91-489f-9c00-2577540d1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_without_buckets(pdf_path, output_folder):\n",
    "    \"\"\"Process a PDF file without using Google Cloud Storage.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    print(\"Converting PDF to images...\")\n",
    "    image_paths = pdf_to_images(pdf_path, output_folder)\n",
    "\n",
    "    print(\"Extracting text from images...\")\n",
    "    extracted_text = extract_text_from_images(image_paths)\n",
    "\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4ebbef-dc08-48dc-95c4-c633446a03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by removing stopwords, punctuation, and lowercasing.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6713b5a4-6c2b-428a-98af-526d3442386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_score(text1, text2):\n",
    "    \"\"\"Calculate the similarity score between two texts using SBERT.\"\"\"\n",
    "    sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    embeddings1 = sbert_model.encode(text1, convert_to_tensor=True)\n",
    "    embeddings2 = sbert_model.encode(text2, convert_to_tensor=True)\n",
    "    cosine_similarity = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f0a40d-f80c-4fd3-ba62-38c1042f8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(student_pdf_path, teacher_answer_path, output_folder):\n",
    "    # Extract text from student's PDF\n",
    "    print(\"Processing student's PDF...\")\n",
    "    student_text = process_pdf_without_buckets(student_pdf_path, output_folder)\n",
    "    \n",
    "    # If teacher's answer is a PDF, extract text; otherwise, read as text\n",
    "    if teacher_answer_path.endswith('.pdf'):\n",
    "        print(\"Processing teacher's PDF...\")\n",
    "        teacher_text = process_pdf_without_buckets(teacher_answer_path, output_folder)\n",
    "    else:\n",
    "        with open(teacher_answer_path, 'r') as file:\n",
    "            teacher_text = file.read()\n",
    "    \n",
    "    # Preprocess both texts\n",
    "    print(\"Preprocessing texts...\")\n",
    "    student_text_processed = preprocess_text(student_text)\n",
    "    teacher_text_processed = preprocess_text(teacher_text)\n",
    "    \n",
    "    # Calculate similarity score\n",
    "    print(\"Calculating similarity score...\")\n",
    "    similarity_score = get_similarity_score(student_text_processed, teacher_text_processed)\n",
    "    \n",
    "    # Assign marks based on similarity score (example: out of 10)\n",
    "    marks = round(similarity_score * 10, 2)\n",
    "    \n",
    "    print(f\"Similarity Score: {similarity_score}\")\n",
    "    print(f\"Marks Awarded: {marks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8391aa1-2281-4a59-a9e5-c2961c98b889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's PDF...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Preprocessing texts...\n",
      "Calculating similarity score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.7783663272857666\n",
      "Marks Awarded: 7.78\n"
     ]
    }
   ],
   "source": [
    "student_pdf_path = \"/home/dhruv/Desktop/CloudOCR/myAnswer.pdf\"\n",
    "teacher_answer_path = \"/home/dhruv/Desktop/CloudOCR/teacher_answer.txt\"\n",
    "output_folder = \"output_images\"\n",
    "\n",
    "main(student_pdf_path, teacher_answer_path, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ed8a8-ae41-42c2-8372-2890eba41ef0",
   "metadata": {},
   "source": [
    "## Entire Paper stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046dc219-28bf-4f7d-92d5-8b2983010168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "from google.cloud import vision\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf997f6-4ed5-472c-b192-dd0443660d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_questions_from_pdf(pdf_path):\n",
    "    \"\"\"Extract questions and their details from PDF with improved parsing.\"\"\"\n",
    "    \n",
    "    def pdf_to_images(pdf_path, output_folder='temp_images'):\n",
    "        \"\"\"Convert PDF to images.\"\"\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        images = convert_from_path(pdf_path)\n",
    "        image_paths = []\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            image_path = f\"{output_folder}/page_{i + 1}.jpg\"\n",
    "            image.save(image_path, \"JPEG\")\n",
    "            image_paths.append(image_path)\n",
    "            \n",
    "        return image_paths\n",
    "\n",
    "    def extract_text_from_images(image_paths):\n",
    "        \"\"\"Extract text using Google Cloud Vision.\"\"\"\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "        all_text = \"\"\n",
    "        \n",
    "        for image_path in image_paths:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                content = image_file.read()\n",
    "            \n",
    "            image = vision.Image(content=content)\n",
    "            response = client.document_text_detection(image=image)\n",
    "            \n",
    "            if response.error.message:\n",
    "                raise Exception(f\"Error processing {image_path}: {response.error.message}\")\n",
    "                \n",
    "            all_text += response.full_text_annotation.text + \"\\n\"\n",
    "            \n",
    "        return all_text\n",
    "\n",
    "    def parse_questions(text):\n",
    "        \"\"\"Parse questions with multiple pattern matching attempts.\"\"\"\n",
    "        # Print the extracted text for debugging\n",
    "        print(\"\\nExtracted text from PDF:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(text)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Try different question patterns\n",
    "        patterns = [\n",
    "            r'Q\\.?\\s*(\\d+)\\.(.*?)(?=Q\\.?\\s*\\d+\\.|$)',  # Q. 1. or Q1.\n",
    "            r'Question\\s*(\\d+)[.:]?(.*?)(?=Question\\s*\\d+|$)',  # Question 1:\n",
    "            r'(\\d+)\\.(.*?)(?=\\d+\\.|$)',  # 1.\n",
    "            r'$$(\\d+)$$(.*?)(?=$$\\d+$$|$)'  # (1)\n",
    "        ]\n",
    "        \n",
    "        marks_patterns = [\n",
    "            r'$$(\\d+)\\s*marks?$$',  # (5 marks) or (5 mark)\n",
    "            r'(\\d+)\\s*marks?',      # 5 marks\n",
    "            r'$$(\\d+)\\s*marks?$$'   # [5 marks]\n",
    "        ]\n",
    "        \n",
    "        questions = {}\n",
    "        \n",
    "        # Try each pattern until we find questions\n",
    "        for pattern in patterns:\n",
    "            matches = list(re.finditer(pattern, text, re.DOTALL | re.IGNORECASE))\n",
    "            if matches:\n",
    "                print(f\"\\nFound questions using pattern: {pattern}\")\n",
    "                for match in matches:\n",
    "                    q_num = match.group(1)\n",
    "                    q_text = match.group(2).strip()\n",
    "                    \n",
    "                    # Try to extract marks\n",
    "                    marks = 0\n",
    "                    for marks_pattern in marks_patterns:\n",
    "                        marks_match = re.search(marks_pattern, q_text, re.IGNORECASE)\n",
    "                        if marks_match:\n",
    "                            marks = int(marks_match.group(1))\n",
    "                            # Remove marks pattern from question text\n",
    "                            q_text = re.sub(marks_pattern, '', q_text, flags=re.IGNORECASE).strip()\n",
    "                            break\n",
    "                    \n",
    "                    questions[q_num] = {\n",
    "                        'question_text': q_text,\n",
    "                        'marks': marks\n",
    "                    }\n",
    "                    print(f\"\\nFound Question {q_num}:\")\n",
    "                    print(f\"Text: {q_text[:100]}...\")  # Print first 100 chars\n",
    "                    print(f\"Marks: {marks}\")\n",
    "                \n",
    "                if questions:  # If we found any questions, stop trying patterns\n",
    "                    break\n",
    "        \n",
    "        return questions\n",
    "\n",
    "    try:\n",
    "        # Process PDF\n",
    "        print(\"Converting PDF to images...\")\n",
    "        image_paths = pdf_to_images(pdf_path)\n",
    "        \n",
    "        print(\"Extracting text from images...\")\n",
    "        extracted_text = extract_text_from_images(image_paths)\n",
    "        \n",
    "        print(\"Parsing questions...\")\n",
    "        questions = parse_questions(extracted_text)\n",
    "        \n",
    "        # Cleanup temporary images\n",
    "        for image_path in image_paths:\n",
    "            os.remove(image_path)\n",
    "        os.rmdir('temp_images')\n",
    "        \n",
    "        if not questions:\n",
    "            print(\"No questions were found in the text.\")\n",
    "            return None\n",
    "            \n",
    "        return questions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1a92756-0462-4ca2-a4df-56dabe23a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionPaper:\n",
    "    def __init__(self, paper_id):\n",
    "        self.paper_id = paper_id\n",
    "        self.questions = {}\n",
    "        self.total_marks = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_text_from_pdf(pdf_path):\n",
    "        \"\"\"Extract text from PDF using Google Cloud Vision.\"\"\"\n",
    "        try:\n",
    "            # Convert PDF to images\n",
    "            print(\"Converting PDF to images...\")\n",
    "            images = convert_from_path(pdf_path)\n",
    "            \n",
    "            # Setup Google Cloud Vision\n",
    "            client = vision.ImageAnnotatorClient()\n",
    "            extracted_text = \"\"\n",
    "            \n",
    "            print(\"Extracting text from images...\")\n",
    "            for i, image in enumerate(images):\n",
    "                # Save image temporarily\n",
    "                image_path = f\"temp_page_{i}.jpg\"\n",
    "                image.save(image_path, \"JPEG\")\n",
    "                \n",
    "                # Extract text from image\n",
    "                with open(image_path, \"rb\") as image_file:\n",
    "                    content = image_file.read()\n",
    "                image = vision.Image(content=content)\n",
    "                response = client.document_text_detection(image=image)\n",
    "                extracted_text += response.full_text_annotation.text + \"\\n\"\n",
    "                \n",
    "                # Clean up temp image\n",
    "                os.remove(image_path)\n",
    "            \n",
    "            return extracted_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in text extraction: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_questions(text):\n",
    "        \"\"\"Parse questions from extracted text.\"\"\"\n",
    "        # Print the extracted text for debugging\n",
    "        print(\"\\nExtracted text:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(text)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        questions = {}\n",
    "        \n",
    "        # Pattern to match questions with parts\n",
    "        pattern = r'Q\\.?\\s*(\\d+)([AB]?)\\.?\\s*([^Q]*)(?=Q\\.|$)'\n",
    "        matches = re.finditer(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        \n",
    "        for match in matches:\n",
    "            q_num = match.group(1)\n",
    "            q_part = match.group(2) if match.group(2) else ''\n",
    "            q_text = match.group(3).strip()\n",
    "            \n",
    "            # Extract marks\n",
    "            marks_match = re.search(r'(?:Max\\.\\s*Marks\\s*(\\d+))|(\\d+)\\s*marks?', q_text, re.IGNORECASE)\n",
    "            marks = int(marks_match.group(1) or marks_match.group(2)) if marks_match else 5\n",
    "            \n",
    "            # Clean question text\n",
    "            q_text = re.sub(r'(?:Max\\.\\s*Marks\\s*\\d+)|(?:\\d+\\s*marks?)', '', q_text, re.IGNORECASE)\n",
    "            q_text = re.sub(r'OR', '', q_text)\n",
    "            q_text = ' '.join(q_text.split())  # Clean up whitespace\n",
    "            \n",
    "            question_id = f\"{q_num}{q_part}\"\n",
    "            questions[question_id] = {\n",
    "                'text': q_text,\n",
    "                'marks': marks\n",
    "            }\n",
    "            \n",
    "            # Print parsed question for debugging\n",
    "            print(f\"\\nParsed Q{question_id}:\")\n",
    "            print(f\"Text: {q_text}\")\n",
    "            print(f\"Marks: {marks}\")\n",
    "        \n",
    "        return questions\n",
    "\n",
    "    @classmethod\n",
    "    def from_pdf(cls, pdf_path, paper_id):\n",
    "        \"\"\"Create QuestionPaper instance from PDF file.\"\"\"\n",
    "        paper = cls(paper_id)\n",
    "        \n",
    "        # Extract text from PDF\n",
    "        extracted_text = cls.extract_text_from_pdf(pdf_path)\n",
    "        if not extracted_text:\n",
    "            return None\n",
    "        \n",
    "        # Parse questions\n",
    "        paper.questions = cls.parse_questions(extracted_text)\n",
    "        paper.total_marks = sum(q['marks'] for q in paper.questions.values())\n",
    "        \n",
    "        if paper.questions:\n",
    "            print(f\"\\nSuccessfully extracted {len(paper.questions)} questions\")\n",
    "            print(f\"Total marks: {paper.total_marks}\")\n",
    "        else:\n",
    "            print(\"No questions were extracted from the PDF\")\n",
    "        \n",
    "        return paper\n",
    "\n",
    "    def display_questions(self):\n",
    "        \"\"\"Display formatted questions.\"\"\"\n",
    "        print(f\"\\nQuestion Paper ID: {self.paper_id}\")\n",
    "        print(f\"Total Marks: {self.total_marks}\")\n",
    "        print(\"\\nQuestions:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for q_num, q_data in sorted(self.questions.items()):\n",
    "            print(f\"\\nQuestion {q_num}:\")\n",
    "            print(f\"Text: {q_data['text']}\")  # Changed from 'question_text' to 'text'\n",
    "            print(f\"Marks: {q_data['marks']}\")\n",
    "            if 'model_answer' in q_data:\n",
    "                print(f\"Model Answer: {q_data['model_answer']}\")\n",
    "\n",
    "    def to_dataframe(self):\n",
    "        \"\"\"Convert questions to pandas DataFrame.\"\"\"\n",
    "        questions_list = []\n",
    "        \n",
    "        for q_num, q_data in sorted(self.questions.items()):\n",
    "            row = {\n",
    "                'Question No.': f'Q{q_num}',\n",
    "                'Question': q_data['text'],  # Changed from 'question_text' to 'text'\n",
    "                'Marks': q_data['marks']\n",
    "            }\n",
    "            if 'model_answer' in q_data:\n",
    "                row['Model Answer'] = q_data['model_answer']\n",
    "            questions_list.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(questions_list)\n",
    "        return df\n",
    "\n",
    "    def get_raw_text(self):\n",
    "        \"\"\"Get raw text of all questions.\"\"\"\n",
    "        raw_text = []\n",
    "        for q_num, q_data in sorted(self.questions.items()):\n",
    "            question_text = f\"Q{q_num} {q_data['text']} Max. Marks {q_data['marks']}\"\n",
    "            raw_text.append(question_text)\n",
    "        return '\\n'.join(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b662d1bb-d688-4e49-9c74-3d1bca0bbd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Successfully extracted 3 questions\n",
      "Total marks: 15\n",
      "\n",
      "Question Paper ID: a\n",
      "Total Marks: 15\n",
      "\n",
      "Questions:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question No.</th>\n",
       "      <th>Question</th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>(b)\\nExplain the Hough Transform and its funda...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>(b)\\nDescribe how different noise can be handl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>Analyze the differences and similarities betwe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question No.                                           Question  Marks\n",
       "0           Q1  (b)\\nExplain the Hough Transform and its funda...      5\n",
       "1           Q2  (b)\\nDescribe how different noise can be handl...      5\n",
       "2           Q3  Analyze the differences and similarities betwe...      5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question No.</th>\n",
       "      <th>Question</th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>(b)\\nExplain the Hough Transform and its funda...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>(b)\\nDescribe how different noise can be handl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>Analyze the differences and similarities betwe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question No.                                           Question  Marks\n",
       "0           Q1  (b)\\nExplain the Hough Transform and its funda...      5\n",
       "1           Q2  (b)\\nDescribe how different noise can be handl...      5\n",
       "2           Q3  Analyze the differences and similarities betwe...      5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw Text:\n",
      "Question Paper ID: a\n",
      "Total Marks: 15\n",
      "\n",
      "Questions:\n",
      "--------------------------------------------------\n",
      "\n",
      "Q1 (b)\n",
      "Explain the Hough Transform and its fundamental concepts. Consider the\n",
      "edge pixels detected at coordinates (1,1) and (3,3).\n",
      "[05] Max. Marks 5\n",
      "Q2 (b)\n",
      "Describe how different noise can be handled in image restoration. How can\n",
      "restoration algorithms be applied to reduce or eliminate these types of noise\n",
      "from an image.\n",
      "[05] Max. Marks 5\n",
      "Q3 Analyze the differences and similarities between optical flow and the\n",
      "motion field.\n",
      "[05]\n",
      "PLOT NO. U-15, JVPD SCHEME, BHAKTIVEDANTA SWAMI MARG, VILE PARLE (WEST), MUMBAI - 400056.\n",
      "Tel.: 42335000/42335001 Email: info@djsce.ac.in/ admin@djsce.ac.in Website: www.djsce ac in Max. Marks 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create question paper from PDF\n",
    "pdf_path = \"QPTest-Nocrop.pdf\"\n",
    "paper = QuestionPaper.from_pdf(pdf_path, \"a\")\n",
    "\n",
    "if paper and paper.questions:\n",
    "    # Display questions\n",
    "    paper.display_questions()\n",
    "    \n",
    "    # Get as DataFrame\n",
    "    df = paper.to_dataframe()\n",
    "    display(df)\n",
    "    \n",
    "    # Get raw text\n",
    "    raw_text = paper.get_raw_text()\n",
    "    print(\"\\nRaw Text:\")\n",
    "    print(raw_text)\n",
    "else:\n",
    "    print(\"Failed to extract questions from PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed6ac461-e840-403d-8b4b-7c09e417c577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question No.</th>\n",
       "      <th>Question</th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>(b)\\nExplain the Hough Transform and its funda...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>(b)\\nDescribe how different noise can be handl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>Analyze the differences and similarities betwe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question No.                                           Question  Marks\n",
       "0           Q1  (b)\\nExplain the Hough Transform and its funda...      5\n",
       "1           Q2  (b)\\nDescribe how different noise can be handl...      5\n",
       "2           Q3  Analyze the differences and similarities betwe...      5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c79d0-bcdb-4304-b917-2a7981c1cbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
