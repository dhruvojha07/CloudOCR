{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb388ee-d36b-40ac-88a8-31ebe19afd13",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9702a220-38fe-42e7-b7e7-cea9f16e81ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 17:34:19.238065: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743681859.251674   17619 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743681859.255704   17619 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-03 17:34:19.269003: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from google.cloud import vision\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import spacy\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d77242-a3fa-4e8e-9ba3-2024e43a912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path, output_folder):\n",
    "    \"\"\"Convert a PDF to images, one image per page.\"\"\"\n",
    "    images = convert_from_path(pdf_path)\n",
    "    image_paths = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image_path = f\"{output_folder}/page_{i + 1}.jpg\"\n",
    "        image.save(image_path, \"JPEG\")\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f710b6c1-31e8-4502-a363-9353985eeb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_images(image_paths):\n",
    "    \"\"\"Extract text from a list of image paths using Google Cloud Vision.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    all_text = \"\"\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "        \n",
    "        image = vision.Image(content=content)\n",
    "        response = client.document_text_detection(image=image)\n",
    "\n",
    "        if response.error.message:\n",
    "            raise Exception(f\"Error processing {image_path}: {response.error.message}\")\n",
    "\n",
    "        all_text += response.full_text_annotation.text + \"\\n\"\n",
    "\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87336b21-8035-4e28-b64f-37b5e724880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_without_buckets(pdf_path, output_folder):\n",
    "    \"\"\"Process a PDF file without using Google Cloud Storage.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    print(\"Converting PDF to images...\")\n",
    "    image_paths = pdf_to_images(pdf_path, output_folder)\n",
    "\n",
    "    print(\"Extracting text from images...\")\n",
    "    extracted_text = extract_text_from_images(image_paths)\n",
    "\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e6d8c0-fc01-41ed-b0e1-6bf1ef01a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n+', ' ', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)  \n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_text), ' '.join(filtered_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945eee9e-abdb-4468-acbd-38a6c5f7e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer(student_text, reference_text):\n",
    "    \"\"\"Comprehensive answer evaluation using multiple metrics.\"\"\"\n",
    "    sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    def get_semantic_similarity(text1, text2):\n",
    "        \"\"\"Calculate semantic similarity using SBERT.\"\"\"\n",
    "        embeddings1 = sbert_model.encode(text1, convert_to_tensor=True)\n",
    "        embeddings2 = sbert_model.encode(text2, convert_to_tensor=True)\n",
    "        return util.pytorch_cos_sim(embeddings1, embeddings2).item()\n",
    "\n",
    "    def get_keyword_coverage(student_text, reference_text):\n",
    "        \"\"\"Calculate keyword matching and coverage.\"\"\"\n",
    "        student_words = set(word_tokenize(student_text.lower()))\n",
    "        reference_words = set(word_tokenize(reference_text.lower()))\n",
    "        return len(student_words.intersection(reference_words)) / len(reference_words) if reference_words else 0\n",
    "\n",
    "    def check_length_ratio(student_text, reference_text):\n",
    "        \"\"\"Check if answer length is appropriate.\"\"\"\n",
    "        student_length = len(word_tokenize(student_text))\n",
    "        reference_length = len(word_tokenize(reference_text))\n",
    "        ratio = student_length / reference_length if reference_length > 0 else 0\n",
    "        return min(1.0, ratio if ratio <= 1.5 else 1.5 / ratio)\n",
    "\n",
    "    def check_structure_similarity(student_text, reference_text):\n",
    "        \"\"\"Compare structural elements like paragraphs and sentences.\"\"\"\n",
    "        student_sentences = sent_tokenize(student_text)\n",
    "        reference_sentences = sent_tokenize(reference_text)\n",
    "        \n",
    "        sent_ratio = min(len(student_sentences), len(reference_sentences)) / max(len(student_sentences), len(reference_sentences))\n",
    "        \n",
    "        student_paragraphs = student_text.split('\\n\\n')\n",
    "        reference_paragraphs = reference_text.split('\\n\\n')\n",
    "        para_ratio = min(len(student_paragraphs), len(reference_paragraphs)) / max(len(student_paragraphs), len(reference_paragraphs))\n",
    "        \n",
    "        return (sent_ratio + para_ratio) / 2\n",
    "\n",
    "    def check_key_phrases(student_text, reference_text):\n",
    "        \"\"\"Check for presence of key phrases and concepts.\"\"\"\n",
    "        def get_phrases(text):\n",
    "            words = word_tokenize(text.lower())\n",
    "            phrases = set()\n",
    "            for i in range(len(words)-1):\n",
    "                phrases.add(f\"{words[i]} {words[i+1]}\")\n",
    "                if i < len(words)-2:\n",
    "                    phrases.add(f\"{words[i]} {words[i+1]} {words[i+2]}\")\n",
    "            return phrases\n",
    "        \n",
    "        ref_phrases = get_phrases(reference_text)\n",
    "        student_phrases = get_phrases(student_text)\n",
    "        return len(student_phrases.intersection(ref_phrases)) / len(ref_phrases) if ref_phrases else 0\n",
    "\n",
    "    def check_sequence_alignment(student_text, reference_text):\n",
    "        \"\"\"Check if ideas are presented in a similar sequence.\"\"\"\n",
    "        student_sentences = sent_tokenize(student_text)\n",
    "        reference_sentences = sent_tokenize(reference_text)\n",
    "        \n",
    "        student_emb = sbert_model.encode(student_sentences)\n",
    "        reference_emb = sbert_model.encode(reference_sentences)\n",
    "        \n",
    "        alignment_scores = []\n",
    "        for i in range(min(len(student_emb), len(reference_emb))):\n",
    "            similarity = util.pytorch_cos_sim(student_emb[i], reference_emb[i])\n",
    "            alignment_scores.append(similarity.item())\n",
    "        \n",
    "        return sum(alignment_scores) / len(alignment_scores) if alignment_scores else 0\n",
    "\n",
    "    def check_factual_accuracy(student_text, reference_text):\n",
    "        \"\"\"Check for presence of numerical values and specific facts.\"\"\"\n",
    "        def extract_numbers(text):\n",
    "            return set(re.findall(r'\\d+(?:\\.\\d+)?', text))\n",
    "        \n",
    "        student_numbers = extract_numbers(student_text)\n",
    "        reference_numbers = extract_numbers(reference_text)\n",
    "        \n",
    "        number_accuracy = len(student_numbers.intersection(reference_numbers)) / len(reference_numbers) if reference_numbers else 1.0\n",
    "        return number_accuracy\n",
    "\n",
    "    def check_coherence(text):\n",
    "        \"\"\"Check text coherence using sentence transitions.\"\"\"\n",
    "        sentences = sent_tokenize(text)\n",
    "        if len(sentences) < 2:\n",
    "            return 1.0\n",
    "            \n",
    "        coherence_scores = []\n",
    "        for i in range(len(sentences)-1):\n",
    "            emb1 = sbert_model.encode(sentences[i])\n",
    "            emb2 = sbert_model.encode(sentences[i+1])\n",
    "            similarity = util.pytorch_cos_sim(emb1, emb2)\n",
    "            coherence_scores.append(similarity.item())\n",
    "            \n",
    "        return sum(coherence_scores) / len(coherence_scores)\n",
    "\n",
    "    scores = {\n",
    "        'semantic_similarity': get_semantic_similarity(student_text, reference_text),\n",
    "        'keyword_coverage': get_keyword_coverage(student_text, reference_text),\n",
    "        'length_appropriateness': check_length_ratio(student_text, reference_text),\n",
    "        'structure_similarity': check_structure_similarity(student_text, reference_text),\n",
    "        'key_phrases': check_key_phrases(student_text, reference_text),\n",
    "        'sequence_alignment': check_sequence_alignment(student_text, reference_text),\n",
    "        'factual_accuracy': check_factual_accuracy(student_text, reference_text),\n",
    "        'coherence': check_coherence(student_text)\n",
    "    }\n",
    "\n",
    "    weights = {\n",
    "        'semantic_similarity': 0.25,\n",
    "        'keyword_coverage': 0.15,\n",
    "        'length_appropriateness': 0.10,\n",
    "        'structure_similarity': 0.10,\n",
    "        'key_phrases': 0.15,\n",
    "        'sequence_alignment': 0.10,\n",
    "        'factual_accuracy': 0.10,\n",
    "        'coherence': 0.05\n",
    "    }\n",
    "\n",
    "    final_score = sum(scores[metric] * weights[metric] for metric in scores)\n",
    "\n",
    "    return {\n",
    "        'final_score': final_score,\n",
    "        'details': scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0c065b-546c-46c2-978d-ec03136dae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(student_pdf_path, teacher_answer_path, output_folder):\n",
    "    \"\"\"Main function with comprehensive evaluation.\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"Processing student's submission...\")\n",
    "        student_text = process_pdf_without_buckets(student_pdf_path, output_folder)\n",
    "        \n",
    "        print(\"Processing teacher's answer...\")\n",
    "        if teacher_answer_path.endswith('.pdf'):\n",
    "            teacher_text = process_pdf_without_buckets(teacher_answer_path, output_folder)\n",
    "        else:\n",
    "            with open(teacher_answer_path, 'r') as file:\n",
    "                teacher_text = file.read()\n",
    "        \n",
    "        print(\"Preprocessing texts...\")\n",
    "        student_processed, student_lemmatized = preprocess_text(student_text)\n",
    "        teacher_processed, teacher_lemmatized = preprocess_text(teacher_text)\n",
    "        \n",
    "        print(\"Evaluating answer...\")\n",
    "        evaluation_result = evaluate_answer(student_processed, teacher_processed)\n",
    "        \n",
    "        marks = round(evaluation_result['final_score'] * 10, 2)\n",
    "        \n",
    "        print(\"\\n=== Grading Report ===\")\n",
    "        print(f\"Final Marks: {marks}/10\")\n",
    "        print(\"\\nDetailed Scores:\")\n",
    "        for metric, score in evaluation_result['details'].items():\n",
    "            print(f\"{metric.replace('_', ' ').title()}: {score:.2f}\")\n",
    "        \n",
    "        print(f\"\\nProcessing Time: {time.time() - start_time:.2f} seconds\")\n",
    "        \n",
    "        return evaluation_result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main processing: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e795a3-012f-454c-97d4-2ebacfe7cb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 3.89/10\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.58\n",
      "Keyword Coverage: 0.21\n",
      "Length Appropriateness: 0.31\n",
      "Structure Similarity: 0.63\n",
      "Key Phrases: 0.01\n",
      "Sequence Alignment: 0.24\n",
      "Factual Accuracy: 0.75\n",
      "Coherence: 0.39\n",
      "\n",
      "Processing Time: 8.98 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"/home/dhruv/Desktop/CloudOCR/ProperTesting/Jeet-D038.pdf\"\n",
    "teacher_answer = \"/home/dhruv/Desktop/CloudOCR/ProperTesting/AnswerKey.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87256d16-f2fd-4e93-b478-3c63cf6d46b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Extracting text from images...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TIC\\nmsi\\nare\\nate\\nOur\\nate.\\nate:\\ntes\\ntion\\ndi\\nest\\ner ar\\nans\\nto\\nwer\\nQuestion\\nNos.\\nAsymptotic notions are used to\\ncheck the time st& complexity of\\nalgorithms and to find out which\\nalgorithm is the most time efficient.\\nwhen input size is large enough.\\n2) Big\\nBig O → This is used to\\n0\\nrepresent the worst case of the time\\ncomplexity. This suggests the max time that an algorithm\\nf(n)\\ncan take for\\ncompletion\\ne an\\nthis\\noug\\nsho\\not b\\nare f\\ne in.\\nnk, v\\non w\\nwriti\\nsho\\nПо\\nIn the above graph (g(n) and fen)\\nare functions and\\ncgcn) = 0 (f(n))\\ncg (n) = f(n)\\nif and\\nwe can\\nonly if\\nand n>no.\\nsay that\\nQuestion\\nNos.\\n3\\nthe\\n2) Big. W + This is used to represent\\nbest of time complexity of an\\nalgorithm. This suggests the minimum\\ntime algorithm can can for take for its.\\ncompletion.\\nMarks\\nAwarded\\nf(n)\\n((9cm)\\n(gem = ar from the\\nabove graph we can say that f(n) w(eg(n)\\negen) = w(fcns) if and only if\\nfin) & c (g(n))\\nand >no.\\n3) Big 0 - This is used to represent\\nthe average of time complexity of\\nalgorithm. This suggests the\\nan\\naverage time an algorithm can take\\nfor its\\nits completion.\\nho\\nFrom above graph we\\n(296)\\nf(A)\\n(gen)\\ncan say that\\n((g(n)) = f (n) = of (g(n)) (g(n) — O(f(A)\\necg(n) = 0 (f(n) if and only if\\nQuestion\\nNos.\\nRonan Shaver\\n4\\nCi (g (n) <= f(n) <= (a (g(n) and\\nn > ho\\nMarks\\nAwarded\\n5\\nQuestion\\nNos.\\nJ\\n9.2] 1 Insertion at start.\\nAlgo insert start (SPARP.\\nBegin\\n1. If\\n2. ELSE\\n3. SEP\\nAVAIL = NULL\\n\"\\n\"PRINT (\"No Aside available memory\")\\nMarks\\nAwarded\\nAVA NEWNODE = AVAIL and NEWNODE DATA.\\nPPR = SPARP\\nSTART\\n4. WHILE (PTR + NEXT != AHULL\\nSEP PPR = PPR - NEXP\\n=VALUE\\n5. SEP\\nPTR NE &XP\\n6. SEP\\n=\\nNEWNODE NEXT = 8PARP\\nNEWNODE\\n7. SEP\\nSPARP\\n=\\nNEWNODE\\n8. REPURN\\nSPARP\\nY END.\\nExample:\\n1\\nbF\\n+2\\nC 43\\n43\\na\\na\\nb\\nC\\nstart\\nSuppose I have the above circular linked list\\nand I want to insert 0\\n\\'\\nto the algorithm pt 3\\n1.. According\\nthere will ptr\\nthat will traverse the list and\\nvariable that\\nas soon as it reaches the last node with\\nnext address as start\\nit will replace that\\nwith newnode address d and newnode\\nnext will have address of first node\\nand we will set\\nLola Яп\\n\\'d\\n1\\na\\nb\\nstart to new node :\\n2/C\\n3/89\\nb\\nс\\n*\\nSPARP.\\nEN\\nQuestion\\nNos.\\n6\\nMarks\\nAwarded\\nIn this\\nway\\nwe have our node inserted in start.\\nAlgo Delete last (ShART).\\nBegin{\\nIf\\n1. SEP PIR= SPART = NULL\\nPRINT (\"No node to delete\")\\n2\\n2. ELSE SEP PPR= START\\n3. WHILE (PPR - NEXT! - START\\nSEP PREP = PPR\\nSETO POR = PPR-NEXP\\n4. SEP PREP. → NEXT = SPARP\\n15. FREE (PPR)\\nREPURN SPART\\n6.\\nY END.\\nEj\\nb\\nЯ\\n2/ct\\ny3d\\n5/4/a\\nb\\nC j\\nd\\nPART\\nUsing above linked cist we have to\\ndelete\\nptr and\\n·PREP\\nd\\n1\\n4/a. We •set two pointer\\n$ prep. PPR goes ahead and\\nfollow, by keeping behind P.TR.\\nPPR and set. PREP\\nwe reach. 1a our\\nwe changed its\\nWe traverse using\\n, according Once\\nPREP ris on\\naddress, to\\nof PP.R\\n1b\\n.\\n3/d\\nStart and, free the space.\\n5/2/6\\n3\\nQ\\n(116) - YQ1] - 1. ((40) + tree.\\nb\\nC\\na\\nSPARD.\\nNew linked dist\\nis\\n*\\n2C\\n>13/9)\\n3 در 21\\nQuestion\\nNos\\n7\\n03 INFIX (A+B * (C+D) ^E) / (F-G+H*P)\\n→\\nREVERSE) (I *H+G-F)/(e^(D-C) *B+A\\nSumBoh\\nC\\nEXPRESSION.\\nSTACK\\nC\\nP\\n*\\n: (*\\nH\\n: (*\\nΤΗ\\n+\\nа\\n(+\\nIH*\\nTH*G\\n3\\n-\\nJH*G+\\nԲ\\nIH*G+F\\nPH*G+F-\\nTH*G+F-\\n101\\n94*G+F-\\nE\\nA\\nD\\n1\\n164\\n/ CN\\n10^6\\nTH*G+F\\nTH*G+F-E\\nIH*G+F-E\\nTH*G+F-E\\nMarks\\nAwarded\\n8\\nQuestion\\nNos.\\nQ.3) INFIX - (A+B * (C-D)^E) / (F-G+H*I)\\nSYMBOL\\nMarks\\nAwarded\\nSPACK\\nC\\nEXPRESSION\\n1\\nA\\nC\\nA\\n+\\n(\\nA\\nB\\n(+\\nAB\\n*\\n4+*\\nAB\\nC\\nC\\nAB.\\n(++C\\nABC\\n-\\n76+*(-\\nABC\\nD\\nЛ\\nE\\n(+*(-\\n1+ */\\n(+A\\nA B C D\\n-ABCD-\\nABCD - *\\nABCD-E\\n\"ABCD-*Ent\\nABCD - *E^t\\nABCD-*E^+\\nF\\nB\\nABCD - * E^ +F\\n16-\\nABCO`-*E^+F\\nh\\n16\\nAB\\'CD-*E^+FG\"\\n+\\n16+\\nABCD-*E^+FG-\\nH\\n$15+\\nABCD-*E^+FG-M\\n*\\n$1(+*\\nABCD-*E^+FG-H\\nI\\n16+*\\n1\\n:. Past fix expression is\\nABCD - *F^ +FG-HI\\nABCD-*E^ +FG-HI* +\\nABCD - *E^+FG-HI*+/\\nA B C D - X E ^ + F G - H I * +/\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_pdf = \"/home/dhruv/Desktop/CloudOCR/ProperTesting/Krisha-D053.pdf\"\n",
    "student_text = process_pdf_without_buckets(student_pdf, output_dir)\n",
    "student_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33daef-517f-4265-af26-991e13fced32",
   "metadata": {},
   "source": [
    "# Comparison of different metric weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75b9777a-6f6c-476a-8bb6-71aed21940bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "080252e0-2cb7-43d7-841d-9a3e05ba9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weight_combinations():\n",
    "    metrics = [\n",
    "        'semantic_similarity',\n",
    "        'keyword_coverage',\n",
    "        'length_appropriateness',\n",
    "        'structure_similarity',\n",
    "        'key_phrases',\n",
    "        'sequence_alignment',\n",
    "        'factual_accuracy',\n",
    "        'coherence'\n",
    "    ]\n",
    "    \n",
    "    # Predefined reasonable weight combinations that sum to 1\n",
    "    weight_sets = [\n",
    "        [0.20, 0.15, 0.15, 0.10, 0.10, 0.10, 0.10, 0.10],  # Balanced\n",
    "        [0.30, 0.20, 0.10, 0.10, 0.10, 0.10, 0.05, 0.05],  # Emphasis on semantic\n",
    "        [0.25, 0.25, 0.10, 0.10, 0.10, 0.10, 0.05, 0.05],  # Dual emphasis\n",
    "        [0.20, 0.20, 0.20, 0.10, 0.10, 0.10, 0.05, 0.05],  # Triple emphasis\n",
    "        [0.15, 0.15, 0.15, 0.15, 0.10, 0.10, 0.10, 0.10],  # More balanced\n",
    "        [0.25, 0.15, 0.15, 0.15, 0.10, 0.10, 0.05, 0.05],  # Semantic focus\n",
    "        [0.20, 0.20, 0.15, 0.15, 0.10, 0.10, 0.05, 0.05],  # Dual high\n",
    "        [0.30, 0.15, 0.15, 0.10, 0.10, 0.10, 0.05, 0.05],  # High semantic\n",
    "        [0.25, 0.20, 0.15, 0.10, 0.10, 0.10, 0.05, 0.05],  # Balanced high\n",
    "        [0.20, 0.20, 0.15, 0.15, 0.10, 0.10, 0.05, 0.05],  # Even split\n",
    "        [0.25, 0.25, 0.15, 0.10, 0.10, 0.05, 0.05, 0.05],  # Top heavy\n",
    "        [0.20, 0.15, 0.15, 0.15, 0.15, 0.10, 0.05, 0.05],  # Mid spread\n",
    "        [0.30, 0.25, 0.15, 0.10, 0.05, 0.05, 0.05, 0.05],  # Very top heavy\n",
    "        [0.25, 0.20, 0.20, 0.15, 0.05, 0.05, 0.05, 0.05],  # Upper focus\n",
    "        [0.20, 0.20, 0.20, 0.20, 0.05, 0.05, 0.05, 0.05],  # Even top\n",
    "        [0.35, 0.20, 0.15, 0.10, 0.05, 0.05, 0.05, 0.05],  # Semantic priority\n",
    "        [0.30, 0.30, 0.10, 0.10, 0.05, 0.05, 0.05, 0.05],  # Dual priority\n",
    "        [0.25, 0.25, 0.20, 0.10, 0.05, 0.05, 0.05, 0.05],  # Triple top\n",
    "        [0.20, 0.20, 0.20, 0.15, 0.10, 0.05, 0.05, 0.05],  # Balanced top\n",
    "        [0.25, 0.20, 0.15, 0.15, 0.10, 0.05, 0.05, 0.05],  # Graduated\n",
    "        [0.30, 0.20, 0.20, 0.10, 0.05, 0.05, 0.05, 0.05],  # High priority\n",
    "        [0.25, 0.25, 0.15, 0.15, 0.05, 0.05, 0.05, 0.05],  # Dual high priority\n",
    "        [0.20, 0.20, 0.15, 0.15, 0.15, 0.05, 0.05, 0.05],  # Triple mid\n",
    "        [0.30, 0.25, 0.20, 0.10, 0.05, 0.05, 0.03, 0.02],  # Strong top\n",
    "        [0.25, 0.25, 0.25, 0.10, 0.05, 0.05, 0.03, 0.02]   # Triple strong\n",
    "    ]\n",
    "    \n",
    "    weight_combinations = []\n",
    "    for weights in weight_sets:\n",
    "        weight_dict = dict(zip(metrics, weights))\n",
    "        weight_combinations.append(weight_dict)\n",
    "    \n",
    "    return weight_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91575c07-e966-4cc4-b537-5276cb2d9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_two_answers(student_text1, reference_text1, student_text2, reference_text2, max_marks=100):\n",
    "    \"\"\"\n",
    "    Analyze weights performance on two different answers.\n",
    "    max_marks: Maximum marks possible (default 100)\n",
    "    \"\"\"\n",
    "    \n",
    "    weight_combinations = generate_weight_combinations()\n",
    "    \n",
    "    scores1 = evaluate_answer(student_text1, reference_text1)['details']\n",
    "    scores2 = evaluate_answer(student_text2, reference_text2)['details']\n",
    "    \n",
    "    results = []\n",
    "    for weights in weight_combinations:\n",
    "        # Calculate scores for both answers (scaled to max_marks)\n",
    "        final_score1 = sum(scores1[metric] * weights[metric] for metric in weights) * max_marks\n",
    "        final_score2 = sum(scores2[metric] * weights[metric] for metric in weights) * max_marks\n",
    "        \n",
    "        result = {\n",
    "            f'score_answer1 (out of {max_marks})': round(final_score1, 2),\n",
    "            f'score_answer2 (out of {max_marks})': round(final_score2, 2),\n",
    "            'semantic_similarity': round(weights['semantic_similarity'], 3),\n",
    "            'keyword_coverage': round(weights['keyword_coverage'], 3),\n",
    "            'length_appropriateness': round(weights['length_appropriateness'], 3),\n",
    "            'structure_similarity': round(weights['structure_similarity'], 3),\n",
    "            'key_phrases': round(weights['key_phrases'], 3),\n",
    "            'sequence_alignment': round(weights['sequence_alignment'], 3),\n",
    "            'factual_accuracy': round(weights['factual_accuracy'], 3),\n",
    "            'coherence': round(weights['coherence'], 3)\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    df['average_score'] = (df[f'score_answer1 (out of {max_marks})'] + \n",
    "                          df[f'score_answer2 (out of {max_marks})']) / 2\n",
    "    \n",
    "    df['average_score'] = df['average_score'].round(2)\n",
    "    \n",
    "    df = df.sort_values('average_score', ascending=False)\n",
    "    \n",
    "    column_order = [\n",
    "        f'score_answer1 (out of {max_marks})',\n",
    "        f'score_answer2 (out of {max_marks})',\n",
    "        'average_score',\n",
    "        'semantic_similarity',\n",
    "        'keyword_coverage',\n",
    "        'length_appropriateness',\n",
    "        'structure_similarity',\n",
    "        'key_phrases',\n",
    "        'sequence_alignment',\n",
    "        'factual_accuracy',\n",
    "        'coherence'\n",
    "    ]\n",
    "    df = df[column_order]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "792af96c-50bf-4c8b-a78e-7c224015214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_analysis(student_text1, reference_text1,\n",
    "                   student_text2, reference_text2,\n",
    "                   max_marks=100,\n",
    "                   output_path='weight_analysis.csv'):\n",
    "    \"\"\"Analyze and export results to CSV.\"\"\"\n",
    "    \n",
    "    df = analyze_two_answers(\n",
    "        student_text1, reference_text1,\n",
    "        student_text2, reference_text2,\n",
    "        max_marks=max_marks\n",
    "    )\n",
    "    \n",
    "    print(\"\\nWeight Analysis Results:\")\n",
    "    print(\"\\nFirst 5 combinations:\")\n",
    "    display(df.head())\n",
    "    print(\"\\nLast 5 combinations:\")\n",
    "    display(df.tail())\n",
    "    \n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    summary_stats = df[[f'score_answer1 (out of {max_marks})', \n",
    "                       f'score_answer2 (out of {max_marks})', \n",
    "                       'average_score']].describe()\n",
    "    display(summary_stats)\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nFull analysis exported to {output_path}\")\n",
    "    \n",
    "    best_weights = df.iloc[0].drop([f'score_answer1 (out of {max_marks})', \n",
    "                                  f'score_answer2 (out of {max_marks})', \n",
    "                                  'average_score']).to_dict()\n",
    "    return best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "906af149-c60c-47bd-9046-57b49ba6a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n"
     ]
    }
   ],
   "source": [
    "student_pdf_path1 = \"/home/dhruv/Desktop/CloudOCR/myAnswer.pdf\"\n",
    "student_pdf_path2 = \"/home/dhruv/Desktop/CloudOCR/student_answer.pdf\"\n",
    "teacher_answer_path = \"/home/dhruv/Desktop/CloudOCR/teacher_answer.txt\"\n",
    "output_folder = \"output\"\n",
    "\n",
    "student_answer1 = process_pdf_without_buckets(student_pdf_path1, output_folder)\n",
    "\n",
    "student_answer2 = process_pdf_without_buckets(student_pdf_path2, output_folder)\n",
    "with open(teacher_answer_path, 'r') as file:\n",
    "                reference_answer = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f898ae58-bb60-4a3c-92bd-8d32acb0ef00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gray-level slicing is a technique used in image\\nprocessing to highlight certain intensity levels in an\\nimage. There are two types of gray-level slicing:\\n1. Gray-level slicing with background:\\n-\\nIn this method, the pixels within a specific intensity\\nrange are highlighted, while the rest of the image\\nremains unchanged.\\nThis is useful when you want to focus on specific\\nfeatures while keeping the background intact.\\n2. Gray-level slicing without background:\\nIn this method, only the pixels within the specified\\nintensity range are highlighted, and the rest of the\\nimage is set to a constant value like black or white.\\nThis is useful when you want to isolate specific\\nfeatures and remove all other details from the\\nimage.\\nBoth methods involve selecting a range of intensity\\nvalues and applying a transformation to the image\\nbased on those values.\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_answer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fddce83a-3e4f-42a0-a741-ebd1358b8e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"8.\\nGray -Level Slicing w/out background.\\nEnhance a specific range of intensify levels\\nwhile sitting all other pixel values to 0.\\nisclating specific features.\\nGray - Level slicing w/ background:\\nEnhances ce certain range of intensity levels bet\\nretains the rest of Image's intensity levels as\\nare preserving the background.\\nthey\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_answer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd98a940-03fc-428c-aaa8-56a96a6a9360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weight Analysis Results:\n",
      "\n",
      "First 5 combinations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_answer1 (out of 10)</th>\n",
       "      <th>score_answer2 (out of 10)</th>\n",
       "      <th>average_score</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>keyword_coverage</th>\n",
       "      <th>length_appropriateness</th>\n",
       "      <th>structure_similarity</th>\n",
       "      <th>key_phrases</th>\n",
       "      <th>sequence_alignment</th>\n",
       "      <th>factual_accuracy</th>\n",
       "      <th>coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.51</td>\n",
       "      <td>8.35</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.37</td>\n",
       "      <td>8.37</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.30</td>\n",
       "      <td>8.30</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.28</td>\n",
       "      <td>8.24</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.26</td>\n",
       "      <td>8.22</td>\n",
       "      <td>6.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score_answer1 (out of 10)  score_answer2 (out of 10)  average_score  \\\n",
       "15                       4.51                       8.35           6.43   \n",
       "23                       4.37                       8.37           6.37   \n",
       "20                       4.30                       8.30           6.30   \n",
       "12                       4.28                       8.24           6.26   \n",
       "7                        4.26                       8.22           6.24   \n",
       "\n",
       "    semantic_similarity  keyword_coverage  length_appropriateness  \\\n",
       "15                 0.35              0.20                    0.15   \n",
       "23                 0.30              0.25                    0.20   \n",
       "20                 0.30              0.20                    0.20   \n",
       "12                 0.30              0.25                    0.15   \n",
       "7                  0.30              0.15                    0.15   \n",
       "\n",
       "    structure_similarity  key_phrases  sequence_alignment  factual_accuracy  \\\n",
       "15                   0.1         0.05                0.05              0.05   \n",
       "23                   0.1         0.05                0.05              0.03   \n",
       "20                   0.1         0.05                0.05              0.05   \n",
       "12                   0.1         0.05                0.05              0.05   \n",
       "7                    0.1         0.10                0.10              0.05   \n",
       "\n",
       "    coherence  \n",
       "15       0.05  \n",
       "23       0.02  \n",
       "20       0.05  \n",
       "12       0.05  \n",
       "7        0.05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 5 combinations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_answer1 (out of 10)</th>\n",
       "      <th>score_answer2 (out of 10)</th>\n",
       "      <th>average_score</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>keyword_coverage</th>\n",
       "      <th>length_appropriateness</th>\n",
       "      <th>structure_similarity</th>\n",
       "      <th>key_phrases</th>\n",
       "      <th>sequence_alignment</th>\n",
       "      <th>factual_accuracy</th>\n",
       "      <th>coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.79</td>\n",
       "      <td>7.90</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.63</td>\n",
       "      <td>7.92</td>\n",
       "      <td>5.78</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.74</td>\n",
       "      <td>7.82</td>\n",
       "      <td>5.78</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.65</td>\n",
       "      <td>7.73</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.47</td>\n",
       "      <td>7.74</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score_answer1 (out of 10)  score_answer2 (out of 10)  average_score  \\\n",
       "18                       3.79                       7.90           5.85   \n",
       "0                        3.63                       7.92           5.78   \n",
       "11                       3.74                       7.82           5.78   \n",
       "22                       3.65                       7.73           5.69   \n",
       "4                        3.47                       7.74           5.60   \n",
       "\n",
       "    semantic_similarity  keyword_coverage  length_appropriateness  \\\n",
       "18                 0.20              0.20                    0.20   \n",
       "0                  0.20              0.15                    0.15   \n",
       "11                 0.20              0.15                    0.15   \n",
       "22                 0.20              0.20                    0.15   \n",
       "4                  0.15              0.15                    0.15   \n",
       "\n",
       "    structure_similarity  key_phrases  sequence_alignment  factual_accuracy  \\\n",
       "18                  0.15         0.10                0.05              0.05   \n",
       "0                   0.10         0.10                0.10              0.10   \n",
       "11                  0.15         0.15                0.10              0.05   \n",
       "22                  0.15         0.15                0.05              0.05   \n",
       "4                   0.15         0.10                0.10              0.10   \n",
       "\n",
       "    coherence  \n",
       "18       0.05  \n",
       "0        0.10  \n",
       "11       0.05  \n",
       "22       0.05  \n",
       "4        0.10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_answer1 (out of 10)</th>\n",
       "      <th>score_answer2 (out of 10)</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.022000</td>\n",
       "      <td>8.066000</td>\n",
       "      <td>6.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.254378</td>\n",
       "      <td>0.181016</td>\n",
       "      <td>0.212938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.470000</td>\n",
       "      <td>7.730000</td>\n",
       "      <td>5.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.860000</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>5.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.020000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>6.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.230000</td>\n",
       "      <td>8.190000</td>\n",
       "      <td>6.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.510000</td>\n",
       "      <td>8.370000</td>\n",
       "      <td>6.430000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score_answer1 (out of 10)  score_answer2 (out of 10)  average_score\n",
       "count                  25.000000                  25.000000      25.000000\n",
       "mean                    4.022000                   8.066000       6.044800\n",
       "std                     0.254378                   0.181016       0.212938\n",
       "min                     3.470000                   7.730000       5.600000\n",
       "25%                     3.860000                   7.930000       5.900000\n",
       "50%                     4.020000                   8.060000       6.060000\n",
       "75%                     4.230000                   8.190000       6.220000\n",
       "max                     4.510000                   8.370000       6.430000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full analysis exported to weight_analysis.csv\n",
      "\n",
      "Best performing weights:\n",
      "semantic_similarity: 0.35\n",
      "keyword_coverage: 0.2\n",
      "length_appropriateness: 0.15\n",
      "structure_similarity: 0.1\n",
      "key_phrases: 0.05\n",
      "sequence_alignment: 0.05\n",
      "factual_accuracy: 0.05\n",
      "coherence: 0.05\n"
     ]
    }
   ],
   "source": [
    "max_marks = 10\n",
    "\n",
    "best_weights = export_analysis(\n",
    "    student_answer1, reference_answer,\n",
    "    student_answer2, reference_answer,\n",
    "    max_marks=max_marks,\n",
    "    output_path='weight_analysis.csv'\n",
    ")\n",
    "\n",
    "print(\"\\nBest performing weights:\")\n",
    "for metric, weight in best_weights.items():\n",
    "    print(f\"{metric}: {round(weight, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2a4a945-c53e-4c2a-803c-b7e28bb90090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_answer1</th>\n",
       "      <th>score_answer2</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>keyword_coverage</th>\n",
       "      <th>length_appropriateness</th>\n",
       "      <th>structure_similarity</th>\n",
       "      <th>key_phrases</th>\n",
       "      <th>sequence_alignment</th>\n",
       "      <th>factual_accuracy</th>\n",
       "      <th>coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.38</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.28</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.03</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.92</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.84</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.21</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.18</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.11</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.08</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.99</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.97</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.89</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score_answer1  score_answer2  semantic_similarity  keyword_coverage  \\\n",
       "0            2.38           2.38             0.125000          0.125000   \n",
       "1            2.33           2.33             0.117647          0.117647   \n",
       "2            2.28           2.28             0.111111          0.111111   \n",
       "3            2.24           2.24             0.105263          0.105263   \n",
       "4            2.20           2.20             0.100000          0.100000   \n",
       "5            2.20           2.20             0.111111          0.111111   \n",
       "6            2.16           2.16             0.105263          0.105263   \n",
       "7            2.13           2.13             0.100000          0.100000   \n",
       "8            2.10           2.10             0.095238          0.095238   \n",
       "9            2.05           2.05             0.100000          0.100000   \n",
       "10           2.03           2.03             0.095238          0.095238   \n",
       "11           2.00           2.00             0.090909          0.090909   \n",
       "12           1.94           1.94             0.090909          0.090909   \n",
       "13           1.92           1.92             0.086957          0.086957   \n",
       "14           1.84           1.84             0.083333          0.083333   \n",
       "15           2.25           2.25             0.105263          0.105263   \n",
       "16           2.21           2.21             0.100000          0.100000   \n",
       "17           2.18           2.18             0.095238          0.095238   \n",
       "18           2.15           2.15             0.090909          0.090909   \n",
       "19           2.11           2.11             0.095238          0.095238   \n",
       "20           2.08           2.08             0.090909          0.090909   \n",
       "21           2.05           2.05             0.086957          0.086957   \n",
       "22           1.99           1.99             0.086957          0.086957   \n",
       "23           1.97           1.97             0.083333          0.083333   \n",
       "24           1.89           1.89             0.080000          0.080000   \n",
       "\n",
       "    length_appropriateness  structure_similarity  key_phrases  \\\n",
       "0                 0.125000              0.125000     0.125000   \n",
       "1                 0.117647              0.117647     0.117647   \n",
       "2                 0.111111              0.111111     0.111111   \n",
       "3                 0.105263              0.105263     0.105263   \n",
       "4                 0.100000              0.100000     0.100000   \n",
       "5                 0.111111              0.111111     0.111111   \n",
       "6                 0.105263              0.105263     0.105263   \n",
       "7                 0.100000              0.100000     0.100000   \n",
       "8                 0.095238              0.095238     0.095238   \n",
       "9                 0.100000              0.100000     0.100000   \n",
       "10                0.095238              0.095238     0.095238   \n",
       "11                0.090909              0.090909     0.090909   \n",
       "12                0.090909              0.090909     0.090909   \n",
       "13                0.086957              0.086957     0.086957   \n",
       "14                0.083333              0.083333     0.083333   \n",
       "15                0.105263              0.105263     0.105263   \n",
       "16                0.100000              0.100000     0.100000   \n",
       "17                0.095238              0.095238     0.095238   \n",
       "18                0.090909              0.090909     0.090909   \n",
       "19                0.095238              0.095238     0.095238   \n",
       "20                0.090909              0.090909     0.090909   \n",
       "21                0.086957              0.086957     0.086957   \n",
       "22                0.086957              0.086957     0.086957   \n",
       "23                0.083333              0.083333     0.083333   \n",
       "24                0.080000              0.080000     0.080000   \n",
       "\n",
       "    sequence_alignment  factual_accuracy  coherence  \n",
       "0             0.125000          0.125000   0.125000  \n",
       "1             0.117647          0.117647   0.176471  \n",
       "2             0.111111          0.111111   0.222222  \n",
       "3             0.105263          0.105263   0.263158  \n",
       "4             0.100000          0.100000   0.300000  \n",
       "5             0.111111          0.166667   0.166667  \n",
       "6             0.105263          0.157895   0.210526  \n",
       "7             0.100000          0.150000   0.250000  \n",
       "8             0.095238          0.142857   0.285714  \n",
       "9             0.100000          0.200000   0.200000  \n",
       "10            0.095238          0.190476   0.238095  \n",
       "11            0.090909          0.181818   0.272727  \n",
       "12            0.090909          0.227273   0.227273  \n",
       "13            0.086957          0.217391   0.260870  \n",
       "14            0.083333          0.250000   0.250000  \n",
       "15            0.157895          0.157895   0.157895  \n",
       "16            0.150000          0.150000   0.200000  \n",
       "17            0.142857          0.142857   0.238095  \n",
       "18            0.136364          0.136364   0.272727  \n",
       "19            0.142857          0.190476   0.190476  \n",
       "20            0.136364          0.181818   0.227273  \n",
       "21            0.130435          0.173913   0.260870  \n",
       "22            0.130435          0.217391   0.217391  \n",
       "23            0.125000          0.208333   0.250000  \n",
       "24            0.120000          0.240000   0.240000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7be82c-8f7f-4579-840b-9263fb005b34",
   "metadata": {},
   "source": [
    "# Comparison of different similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21679ca6-8f34-4b7a-a144-6745efa456c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7234b9e6b77d4535b5f4146e0475d17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_attentions\": true,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61cba7528b14078965aa1460ab708ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870110905fed47c2b97fad9bfb559fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e546ed69b74f24b76f0bba68d64611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer.json\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdf6e477d4548d7842bd21807880cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file model.safetensors from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n",
      "[nltk_data] Downloading package punkt to /home/dhruv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/dhruv/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer  \n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b8668fa3-7b11-45c0-a054-5e7fca97b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, candidate):\n",
    "    \"\"\"Calculate BLEU score.\"\"\"\n",
    "    smoothie = SmoothingFunction().method1\n",
    "    reference_tokens = reference.split()\n",
    "    candidate_tokens = candidate.split()\n",
    "    return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoothie)\n",
    "\n",
    "def calculate_rouge(reference, candidate):\n",
    "    \"\"\"Calculate ROUGE scores.\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, candidate)\n",
    "    return {\n",
    "        'rouge1': scores['rouge1'].fmeasure,\n",
    "        'rouge2': scores['rouge2'].fmeasure,\n",
    "        'rougeL': scores['rougeL'].fmeasure\n",
    "    }\n",
    "\n",
    "def calculate_meteor(reference, candidate):\n",
    "    \"\"\"Calculate METEOR score.\"\"\"\n",
    "    return meteor_score([reference.split()], candidate.split())\n",
    "\n",
    "def calculate_bert_score(reference, candidate):\n",
    "    \"\"\"Calculate BERTScore.\"\"\"\n",
    "    P, R, F1 = bert_score([candidate], [reference], lang='en')\n",
    "    return {\n",
    "        'bert_precision': P.mean().item(),\n",
    "        'bert_recall': R.mean().item(),\n",
    "        'bert_f1': F1.mean().item()\n",
    "    }\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    \"\"\"Calculate perplexity.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "    model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    return torch.exp(outputs.loss).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "016aa4b6-3f32-41d5-9fd6-b181e1899bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(student_text1, student_text2, reference_text):\n",
    "    \"\"\"Compare all metrics between two student answers.\"\"\"\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # Calculate metrics for first answer\n",
    "    metrics['answer1_bleu'] = calculate_bleu(reference_text, student_text1)\n",
    "    metrics['answer1_meteor'] = calculate_meteor(reference_text, student_text1)\n",
    "    \n",
    "    rouge1 = calculate_rouge(reference_text, student_text1)\n",
    "    metrics['answer1_rouge1'] = rouge1['rouge1']\n",
    "    metrics['answer1_rouge2'] = rouge1['rouge2']\n",
    "    metrics['answer1_rougeL'] = rouge1['rougeL']\n",
    "    \n",
    "    bert1 = calculate_bert_score(reference_text, student_text1)\n",
    "    metrics['answer1_bert_f1'] = bert1['bert_f1']\n",
    "    \n",
    "    metrics['answer1_perplexity'] = calculate_perplexity(student_text1)\n",
    "    \n",
    "    # Calculate metrics for second answer\n",
    "    metrics['answer2_bleu'] = calculate_bleu(reference_text, student_text2)\n",
    "    metrics['answer2_meteor'] = calculate_meteor(reference_text, student_text2)\n",
    "    \n",
    "    rouge2 = calculate_rouge(reference_text, student_text2)\n",
    "    metrics['answer2_rouge1'] = rouge2['rouge1']\n",
    "    metrics['answer2_rouge2'] = rouge2['rouge2']\n",
    "    metrics['answer2_rougeL'] = rouge2['rougeL']\n",
    "    \n",
    "    bert2 = calculate_bert_score(reference_text, student_text2)\n",
    "    metrics['answer2_bert_f1'] = bert2['bert_f1']\n",
    "    \n",
    "    metrics['answer2_perplexity'] = calculate_perplexity(student_text2)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4bff4821-c557-4bba-9728-480737c2b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_df(metrics_dict):\n",
    "    \"\"\"Create a formatted DataFrame from metrics.\"\"\"\n",
    "    \n",
    "    # Reorganize data for DataFrame\n",
    "    data = {\n",
    "        'Metric': [\n",
    "            'BLEU Score',\n",
    "            'METEOR Score',\n",
    "            'ROUGE-1',\n",
    "            'ROUGE-2',\n",
    "            'ROUGE-L',\n",
    "            'BERTScore (F1)',\n",
    "            'Perplexity'\n",
    "        ],\n",
    "        'Answer 1': [\n",
    "            metrics_dict['answer1_bleu'],\n",
    "            metrics_dict['answer1_meteor'],\n",
    "            metrics_dict['answer1_rouge1'],\n",
    "            metrics_dict['answer1_rouge2'],\n",
    "            metrics_dict['answer1_rougeL'],\n",
    "            metrics_dict['answer1_bert_f1'],\n",
    "            metrics_dict['answer1_perplexity']\n",
    "        ],\n",
    "        'Answer 2': [\n",
    "            metrics_dict['answer2_bleu'],\n",
    "            metrics_dict['answer2_meteor'],\n",
    "            metrics_dict['answer2_rouge1'],\n",
    "            metrics_dict['answer2_rouge2'],\n",
    "            metrics_dict['answer2_rougeL'],\n",
    "            metrics_dict['answer2_bert_f1'],\n",
    "            metrics_dict['answer2_perplexity']\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add difference column\n",
    "    df['Difference (A1 - A2)'] = df['Answer 1'] - df['Answer 2']\n",
    "    \n",
    "    # Round all numeric columns to 3 decimal places\n",
    "    numeric_columns = ['Answer 1', 'Answer 2', 'Difference (A1 - A2)']\n",
    "    df[numeric_columns] = df[numeric_columns].round(3)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1ae18d5a-771d-4891-abe2-8df292ff2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_answers(student_text1, student_text2, reference_text, output_path='metric_comparison.csv'):\n",
    "    \"\"\"Main function to analyze and compare two answers.\"\"\"\n",
    "    \n",
    "    print(\"Calculating metrics...\")\n",
    "    metrics = compare_metrics(student_text1, student_text2, reference_text)\n",
    "    \n",
    "    print(\"Creating comparison DataFrame...\")\n",
    "    df = create_comparison_df(metrics)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nMetric Comparison Results:\")\n",
    "    display(df)\n",
    "    \n",
    "    # Export to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nResults exported to {output_path}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c7774ac-1114-49d9-a08d-5224ee03f6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/vocab.json\n",
      "loading file merges.txt from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/tokenizer.json\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/model.safetensors\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n",
      "loading file merges.txt from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n",
      "loading file tokenizer.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/vocab.json\n",
      "loading file merges.txt from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/tokenizer.json\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/model.safetensors\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n",
      "loading file merges.txt from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n",
      "loading file tokenizer.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/dhruv/snap/jupyterlab-desktop/common/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating comparison DataFrame...\n",
      "\n",
      "Metric Comparison Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Answer 1</th>\n",
       "      <th>Answer 2</th>\n",
       "      <th>Difference (A1 - A2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLEU Score</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.529</td>\n",
       "      <td>-0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METEOR Score</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.745</td>\n",
       "      <td>-0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROUGE-1</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROUGE-2</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROUGE-L</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.786</td>\n",
       "      <td>-0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BERTScore (F1)</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.922</td>\n",
       "      <td>-0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Perplexity</td>\n",
       "      <td>238.497</td>\n",
       "      <td>13.205</td>\n",
       "      <td>225.292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric  Answer 1  Answer 2  Difference (A1 - A2)\n",
       "0      BLEU Score     0.006     0.529                -0.523\n",
       "1    METEOR Score     0.111     0.745                -0.634\n",
       "2         ROUGE-1     0.359     0.847                -0.488\n",
       "3         ROUGE-2     0.108     0.683                -0.575\n",
       "4         ROUGE-L     0.223     0.786                -0.563\n",
       "5  BERTScore (F1)     0.843     0.922                -0.079\n",
       "6      Perplexity   238.497    13.205               225.292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results exported to metric_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "results_df = analyze_answers(student_answer1, student_answer2, reference_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8c6c48-a789-4ecf-a9c1-95cd4b4c815f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
