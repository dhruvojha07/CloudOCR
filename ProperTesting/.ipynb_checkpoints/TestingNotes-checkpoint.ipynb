{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17795cec-d1b2-4a8c-a759-c52bdd3255ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 10:24:35.828443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743828876.188841    4986 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743828876.308745    4986 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-05 10:24:37.275049: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from google.cloud import vision\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import spacy\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ff8a44-b587-4686-8e63-25554bf4bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path, output_folder):\n",
    "    \"\"\"Convert a PDF to images, one image per page.\"\"\"\n",
    "    images = convert_from_path(pdf_path)\n",
    "    image_paths = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image_path = f\"{output_folder}/page_{i + 1}.jpg\"\n",
    "        image.save(image_path, \"JPEG\")\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4025dff4-52a9-4f13-a3d5-3bd9400c0464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_images(image_paths):\n",
    "    \"\"\"Extract text from a list of image paths using Google Cloud Vision.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    all_text = \"\"\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "        \n",
    "        image = vision.Image(content=content)\n",
    "        response = client.document_text_detection(image=image)\n",
    "\n",
    "        if response.error.message:\n",
    "            raise Exception(f\"Error processing {image_path}: {response.error.message}\")\n",
    "\n",
    "        all_text += response.full_text_annotation.text + \"\\n\"\n",
    "\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad7d460-29a0-4071-ad38-4030efed7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_without_buckets(pdf_path, output_folder):\n",
    "    \"\"\"Process a PDF file without using Google Cloud Storage.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    print(\"Converting PDF to images...\")\n",
    "    image_paths = pdf_to_images(pdf_path, output_folder)\n",
    "\n",
    "    print(\"Extracting text from images...\")\n",
    "    extracted_text = extract_text_from_images(image_paths)\n",
    "\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32435981-4ebb-435d-a707-5329afb25588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n+', ' ', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)  \n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_text), ' '.join(filtered_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553b4e69-f0c7-4ffb-a639-cd9b3f857b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "\n",
    "def evaluate_answer(student_text, reference_text, total_marks):\n",
    "    \"\"\"Comprehensive answer evaluation with scaling based on total marks.\"\"\"\n",
    "    sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    def get_semantic_similarity():\n",
    "        \"\"\"Calculate semantic similarity using SBERT.\"\"\"\n",
    "        embeddings1 = sbert_model.encode(student_text, convert_to_tensor=True)\n",
    "        embeddings2 = sbert_model.encode(reference_text, convert_to_tensor=True)\n",
    "        return util.pytorch_cos_sim(embeddings1, embeddings2).item()\n",
    "\n",
    "    def check_length_ratio():\n",
    "        \"\"\"Check if answer length is appropriate.\"\"\"\n",
    "        student_length = len(word_tokenize(student_text))\n",
    "        reference_length = len(word_tokenize(reference_text))\n",
    "        ratio = student_length / reference_length if reference_length > 0 else 0\n",
    "        return min(1.0, ratio if ratio <= 1.5 else 1.5 / ratio)\n",
    "\n",
    "    def check_key_phrases():\n",
    "        \"\"\"Check for presence of key phrases and concepts.\"\"\"\n",
    "        def get_phrases(text):\n",
    "            words = word_tokenize(text.lower())\n",
    "            return {f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)} | \\\n",
    "                   {f\"{words[i]} {words[i+1]} {words[i+2]}\" for i in range(len(words)-2)}\n",
    "\n",
    "        ref_phrases = get_phrases(reference_text)\n",
    "        student_phrases = get_phrases(student_text)\n",
    "        return len(student_phrases & ref_phrases) / len(ref_phrases) if ref_phrases else 0\n",
    "\n",
    "    def check_sequence_alignment():\n",
    "        \"\"\"Check if ideas are presented in a similar sequence.\"\"\"\n",
    "        student_sentences = sent_tokenize(student_text)\n",
    "        reference_sentences = sent_tokenize(reference_text)\n",
    "        \n",
    "        student_emb = sbert_model.encode(student_sentences)\n",
    "        reference_emb = sbert_model.encode(reference_sentences)\n",
    "        \n",
    "        alignment_scores = [\n",
    "            util.pytorch_cos_sim(student_emb[i], reference_emb[i]).item()\n",
    "            for i in range(min(len(student_emb), len(reference_emb)))\n",
    "        ]\n",
    "        \n",
    "        return sum(alignment_scores) / len(alignment_scores) if alignment_scores else 0\n",
    "\n",
    "    def check_factual_accuracy():\n",
    "        \"\"\"Check for presence of numerical values and specific facts.\"\"\"\n",
    "        extract_numbers = lambda text: set(re.findall(r'\\d+(?:\\.\\d+)?', text))\n",
    "        \n",
    "        student_numbers = extract_numbers(student_text)\n",
    "        reference_numbers = extract_numbers(reference_text)\n",
    "        \n",
    "        return len(student_numbers & reference_numbers) / len(reference_numbers) if reference_numbers else 1.0\n",
    "\n",
    "    def check_coherence():\n",
    "        \"\"\"Check text coherence using sentence transitions.\"\"\"\n",
    "        sentences = sent_tokenize(student_text)\n",
    "        if len(sentences) < 2:\n",
    "            return 1.0\n",
    "            \n",
    "        coherence_scores = [\n",
    "            util.pytorch_cos_sim(\n",
    "                sbert_model.encode(sentences[i]), \n",
    "                sbert_model.encode(sentences[i+1])\n",
    "            ).item()\n",
    "            for i in range(len(sentences)-1)\n",
    "        ]\n",
    "            \n",
    "        return sum(coherence_scores) / len(coherence_scores)\n",
    "\n",
    "    scores = {\n",
    "        'semantic_similarity': get_semantic_similarity(),\n",
    "        'length_appropriateness': check_length_ratio(),\n",
    "        'key_phrases': check_key_phrases(),\n",
    "        'sequence_alignment': check_sequence_alignment(),\n",
    "        'factual_accuracy': check_factual_accuracy(),\n",
    "        'coherence': check_coherence()\n",
    "    }\n",
    "\n",
    "    weights = {\n",
    "        'semantic_similarity': 0.30,\n",
    "        'length_appropriateness': 0.15,\n",
    "        'key_phrases': 0.20,\n",
    "        'sequence_alignment': 0.15,\n",
    "        'factual_accuracy': 0.10,\n",
    "        'coherence': 0.10\n",
    "    }\n",
    "\n",
    "    raw_score = sum(scores[metric] * weights[metric] for metric in scores)\n",
    "    scaled_score = raw_score * total_marks  # Scale the score based on total marks\n",
    "\n",
    "    return {\n",
    "        'final_score': scaled_score,\n",
    "        'details': scores\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b75700b-51ef-4f41-92ba-a863d2692a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def main(student_pdf_path, teacher_answer_path, output_folder, total_marks=10):\n",
    "    \"\"\"Main function with comprehensive evaluation and scaled scoring.\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"Processing student's submission...\")\n",
    "        student_text = process_pdf_without_buckets(student_pdf_path, output_folder)\n",
    "        \n",
    "        print(\"Processing teacher's answer...\")\n",
    "        if teacher_answer_path.endswith('.pdf'):\n",
    "            teacher_text = process_pdf_without_buckets(teacher_answer_path, output_folder)\n",
    "        else:\n",
    "            with open(teacher_answer_path, 'r') as file:\n",
    "                teacher_text = file.read()\n",
    "        \n",
    "        print(\"Preprocessing texts...\")\n",
    "        student_processed, student_lemmatized = preprocess_text(student_text)\n",
    "        teacher_processed, teacher_lemmatized = preprocess_text(teacher_text)\n",
    "        \n",
    "        print(\"Evaluating answer...\")\n",
    "        evaluation_result = evaluate_answer(student_processed, teacher_processed, total_marks)\n",
    "        \n",
    "        marks = round(evaluation_result['final_score'], 2)  # Already scaled in evaluate_answer\n",
    "        \n",
    "        print(\"\\n=== Grading Report ===\")\n",
    "        print(f\"Final Marks: {marks}/{total_marks}\")\n",
    "        print(\"\\nDetailed Scores:\")\n",
    "        for metric, score in evaluation_result['details'].items():\n",
    "            print(f\"{metric.replace('_', ' ').title()}: {score:.2f}\")\n",
    "        \n",
    "        print(f\"\\nProcessing Time: {time.time() - start_time:.2f} seconds\")\n",
    "        \n",
    "        return evaluation_result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main processing: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506b592-c749-42ff-9caa-03a16e383c40",
   "metadata": {},
   "source": [
    "# Jeet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2b96cd-6c49-4cde-8c3e-622dcc80b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 1.06/3\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.55\n",
      "Length Appropriateness: 0.30\n",
      "Key Phrases: 0.01\n",
      "Sequence Alignment: 0.28\n",
      "Factual Accuracy: 0.60\n",
      "Coherence: 0.40\n",
      "\n",
      "Processing Time: 8.45 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Jeet/Jeet-D038-Q1.pdf\"\n",
    "teacher_answer = \"Q1Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cbcb193-7285-46c2-8b87-404e5f2f865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 3.15/7\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.54\n",
      "Length Appropriateness: 1.00\n",
      "Key Phrases: 0.00\n",
      "Sequence Alignment: 0.24\n",
      "Factual Accuracy: 0.67\n",
      "Coherence: 0.37\n",
      "\n",
      "Processing Time: 7.36 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Jeet/Jeet-D038-Q2.pdf\"\n",
    "teacher_answer = \"Q2-i-answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb58e379-3c07-46cc-b6f3-d1a03245ce6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 1.02/5\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.31\n",
      "Length Appropriateness: 0.37\n",
      "Key Phrases: 0.00\n",
      "Sequence Alignment: 0.13\n",
      "Factual Accuracy: 0.27\n",
      "Coherence: 0.10\n",
      "\n",
      "Processing Time: 5.59 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Jeet/Jeet-D038-Q3.pdf\"\n",
    "teacher_answer = \"Q3Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79eeb76-c4f6-44c5-81cc-83f4e5e22ee8",
   "metadata": {},
   "source": [
    "# Joel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6531e5c9-b1ed-42e7-bd33-39ddeda11c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 0.86/3\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.59\n",
      "Length Appropriateness: 0.13\n",
      "Key Phrases: 0.00\n",
      "Sequence Alignment: 0.18\n",
      "Factual Accuracy: 0.40\n",
      "Coherence: 0.23\n",
      "\n",
      "Processing Time: 7.03 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Joel/Joel-D041-Q1.pdf\"\n",
    "teacher_answer = \"Q1Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc2f415d-813c-407d-b842-9c81aa03d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 3.09/7\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.62\n",
      "Length Appropriateness: 0.90\n",
      "Key Phrases: 0.04\n",
      "Sequence Alignment: 0.28\n",
      "Factual Accuracy: 0.36\n",
      "Coherence: 0.37\n",
      "\n",
      "Processing Time: 7.80 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Joel/Joel-D041-Q2.pdf\"\n",
    "teacher_answer = \"Q2-ii-answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8721615-3032-4a29-b235-d2d004a59215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 1.51/5\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.46\n",
      "Length Appropriateness: 0.63\n",
      "Key Phrases: 0.00\n",
      "Sequence Alignment: 0.18\n",
      "Factual Accuracy: 0.27\n",
      "Coherence: 0.17\n",
      "\n",
      "Processing Time: 6.72 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Joel/Joel-D041-Q3.pdf\"\n",
    "teacher_answer = \"Q3Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ed841-cf38-42d3-9cdd-50986741539a",
   "metadata": {},
   "source": [
    "# Kalp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1293308a-890e-4f29-8561-a79a2d1dc3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 0.74/3\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.50\n",
      "Length Appropriateness: 0.19\n",
      "Key Phrases: 0.01\n",
      "Sequence Alignment: 0.16\n",
      "Factual Accuracy: 0.20\n",
      "Coherence: 0.21\n",
      "\n",
      "Processing Time: 6.34 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Kalp/Kalp-D043-Q1.pdf\"\n",
    "teacher_answer = \"Q1Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "579789b8-a2fc-4cf1-a897-6ecfbb03e047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 3.87/7\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.72\n",
      "Length Appropriateness: 1.00\n",
      "Key Phrases: 0.09\n",
      "Sequence Alignment: 0.41\n",
      "Factual Accuracy: 0.82\n",
      "Coherence: 0.26\n",
      "\n",
      "Processing Time: 10.11 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Kalp/Kalp-D043-Q2.pdf\"\n",
    "teacher_answer = \"Q2-ii-answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9348fb3-4d0f-4dbe-855f-b626f7fa350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 1.45/5\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.39\n",
      "Length Appropriateness: 0.51\n",
      "Key Phrases: 0.00\n",
      "Sequence Alignment: 0.21\n",
      "Factual Accuracy: 0.33\n",
      "Coherence: 0.30\n",
      "\n",
      "Processing Time: 6.51 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Kalp/Kalp-D043-Q3.pdf\"\n",
    "teacher_answer = \"Q3Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e4d6e-9f72-410c-9d03-258997fdbb57",
   "metadata": {},
   "source": [
    "# Krisha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcf70739-1f6a-415a-9f72-abd7fe926cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 1.09/3\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.64\n",
      "Length Appropriateness: 0.36\n",
      "Key Phrases: 0.01\n",
      "Sequence Alignment: 0.20\n",
      "Factual Accuracy: 0.60\n",
      "Coherence: 0.27\n",
      "\n",
      "Processing Time: 7.56 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Krisha/Krisha-D053-Q1.pdf\"\n",
    "teacher_answer = \"Q1Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c4a81b0-d5b9-4843-909f-b005b48d8a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 2.69/7\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.47\n",
      "Length Appropriateness: 0.74\n",
      "Key Phrases: 0.00\n",
      "Sequence Alignment: 0.13\n",
      "Factual Accuracy: 0.89\n",
      "Coherence: 0.24\n",
      "\n",
      "Processing Time: 7.41 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Krisha/Krisha-D053-Q2.pdf\"\n",
    "teacher_answer = \"Q2-i-answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29adbb4e-8dff-4fb2-a7d0-9bf62f4196fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 1.25/5\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.29\n",
      "Length Appropriateness: 0.49\n",
      "Key Phrases: 0.00\n",
      "Sequence Alignment: 0.19\n",
      "Factual Accuracy: 0.27\n",
      "Coherence: 0.36\n",
      "\n",
      "Processing Time: 5.56 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Krisha/Krisha-D053-Q3.pdf\"\n",
    "teacher_answer = \"Q3Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a69a4-90f0-416e-89a5-55a67ff907f6",
   "metadata": {},
   "source": [
    "# Mehika\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cd2be1a-340c-42f9-829c-b9ddc9d5c553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 1.1/3\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.52\n",
      "Length Appropriateness: 0.49\n",
      "Key Phrases: 0.03\n",
      "Sequence Alignment: 0.24\n",
      "Factual Accuracy: 0.60\n",
      "Coherence: 0.37\n",
      "\n",
      "Processing Time: 7.00 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Mehika/Mehika-D062-Q1.pdf\"\n",
    "teacher_answer = \"Q1Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8745491-2204-46b6-9345-b63247dc2d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 3.14/7\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.55\n",
      "Length Appropriateness: 0.80\n",
      "Key Phrases: 0.08\n",
      "Sequence Alignment: 0.20\n",
      "Factual Accuracy: 0.73\n",
      "Coherence: 0.44\n",
      "\n",
      "Processing Time: 14.53 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Mehika/Mehika-D062-Q2.pdf\"\n",
    "teacher_answer = \"Q2-ii-answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d09e1104-1948-47d6-9865-11dd2c328108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student's submission...\n",
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Processing teacher's answer...\n",
      "Preprocessing texts...\n",
      "Evaluating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grading Report ===\n",
      "Final Marks: 1.88/5\n",
      "\n",
      "Detailed Scores:\n",
      "Semantic Similarity: 0.42\n",
      "Length Appropriateness: 0.78\n",
      "Key Phrases: 0.00\n",
      "Sequence Alignment: 0.28\n",
      "Factual Accuracy: 0.40\n",
      "Coherence: 0.48\n",
      "\n",
      "Processing Time: 8.17 seconds\n"
     ]
    }
   ],
   "source": [
    "student_pdf = \"Mehika/Mehika-D062-Q3.pdf\"\n",
    "teacher_answer = \"Q3Answer.txt\"\n",
    "output_dir = \"output_images\"\n",
    "\n",
    "result = main(student_pdf, teacher_answer, output_dir, total_marks=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197fce1e-2747-48f4-a1c2-99c66c4abb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
