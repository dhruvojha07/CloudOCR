{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85bb6553-c426-4b7e-8ad4-db20ca40e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from google.cloud import vision\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d16ba3-4606-4264-82c1-5d23d1ac7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     \"\"\"Extract text from PDF using Google Cloud Vision.\"\"\"\n",
    "#     # Convert PDF to images\n",
    "#     print(\"Converting PDF to images...\")\n",
    "#     images = convert_from_path(pdf_path)\n",
    "    \n",
    "#     # Setup Google Cloud Vision\n",
    "#     client = vision.ImageAnnotatorClient()\n",
    "#     extracted_text = \"\"\n",
    "    \n",
    "#     print(\"Extracting text from images...\")\n",
    "#     for i, image in enumerate(images):\n",
    "#         # Save image temporarily\n",
    "#         image_path = f\"temp_page_{i}.jpg\"\n",
    "#         image.save(image_path, \"JPEG\")\n",
    "        \n",
    "#         # Extract text from image\n",
    "#         with open(image_path, \"rb\") as image_file:\n",
    "#             content = image_file.read()\n",
    "#         image = vision.Image(content=content)\n",
    "#         response = client.document_text_detection(image=image)\n",
    "#         extracted_text += response.full_text_annotation.text + \"\\n\"\n",
    "        \n",
    "#         # Clean up temp image\n",
    "#         os.remove(image_path)\n",
    "    \n",
    "#     return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610e62a7-b2bc-4e5b-a695-e6b69bbd7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_questions(text):\n",
    "#     \"\"\"Extract questions, numbers, and marks from text.\"\"\"\n",
    "#     # Split text into questions\n",
    "#     questions = []\n",
    "    \n",
    "#     # Split by question numbers (Q1, Q2, etc.)\n",
    "#     splits = re.split(r'Q\\.?\\s*\\d+[A-Z]?|OR', text)\n",
    "    \n",
    "#     for i, q_text in enumerate(splits):\n",
    "#         if not q_text.strip():\n",
    "#             continue\n",
    "            \n",
    "#         # Extract marks\n",
    "#         marks_match = re.search(r'(\\d+)\\s*marks', q_text, re.IGNORECASE)\n",
    "#         marks = int(marks_match.group(1)) if marks_match else 0\n",
    "        \n",
    "#         # Clean question text\n",
    "#         clean_text = re.sub(r'(\\d+)\\s*marks|Max\\.?\\s*Marks|^\\s*[A-Z]\\s*', '', q_text, flags=re.IGNORECASE)\n",
    "#         clean_text = ' '.join(clean_text.split())\n",
    "        \n",
    "#         questions.append({\n",
    "#             'question_number': i,\n",
    "#             'question_text': clean_text.strip(),\n",
    "#             'marks': marks\n",
    "#         })\n",
    "    \n",
    "#     return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c2070b3-6cda-4203-a5e5-221ef594af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_question_paper_df(questions):\n",
    "#     \"\"\"Create a clean DataFrame from questions.\"\"\"\n",
    "#     df = pd.DataFrame(questions)\n",
    "    \n",
    "#     # Rename columns for clarity\n",
    "#     df.columns = ['Question No.', 'Question', 'Marks']\n",
    "    \n",
    "#     # Clean up question numbers\n",
    "#     df['Question No.'] = df.index + 1\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# def save_question_paper(df, excel_path, json_path):\n",
    "#     \"\"\"Save question paper in multiple formats.\"\"\"\n",
    "#     # Save as Excel\n",
    "#     df.to_excel(excel_path, index=False, sheet_name='Question Paper')\n",
    "#     print(f\"Saved question paper to Excel: {excel_path}\")\n",
    "    \n",
    "#     # Save as JSON\n",
    "#     questions_dict = df.to_dict(orient='records')\n",
    "#     with open(json_path, 'w') as f:\n",
    "#         json.dump(questions_dict, f, indent=2)\n",
    "#     print(f\"Saved question paper to JSON: {json_path}\")\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85873a4-ec94-48db-92f2-65eb61ee8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_question_paper(pdf_path, output_folder='output'):\n",
    "#     \"\"\"Process question paper and save in multiple formats.\"\"\"\n",
    "#     # Create output folder if it doesn't exist\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "#     # Extract text from PDF\n",
    "#     text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "#     # Extract questions\n",
    "#     questions = extract_questions(text)\n",
    "    \n",
    "#     # Create DataFrame\n",
    "#     df = create_question_paper_df(questions)\n",
    "    \n",
    "#     # Save in multiple formats\n",
    "#     excel_path = os.path.join(output_folder, 'question_paper.xlsx')\n",
    "#     json_path = os.path.join(output_folder, 'question_paper.json')\n",
    "#     save_question_paper(df, excel_path, json_path)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3085b1-4a14-4f70-8c07-703ecfb4b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class QuestionPaper:\n",
    "#     def __init__(self, paper_id):\n",
    "#         self.paper_id = paper_id\n",
    "#         self.questions = {}\n",
    "#         self.total_marks = 0\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_pdf(cls, pdf_path, paper_id):\n",
    "#         \"\"\"Create structured question paper from PDF.\"\"\"\n",
    "#         try:\n",
    "#             paper = cls(paper_id)\n",
    "            \n",
    "#             # Convert PDF to images\n",
    "#             print(\"Converting PDF to images...\")\n",
    "#             image_paths = pdf_to_images(pdf_path)\n",
    "            \n",
    "#             # Extract text\n",
    "#             print(\"Extracting text from images...\")\n",
    "#             extracted_text = extract_text_from_images(image_paths)\n",
    "            \n",
    "#             # Parse questions\n",
    "#             print(\"Parsing questions...\")\n",
    "#             paper.questions = parse_questions(extracted_text)\n",
    "#             paper.total_marks = sum(q['marks'] for q in paper.questions.values())\n",
    "            \n",
    "#             # Cleanup\n",
    "#             for image_path in image_paths:\n",
    "#                 os.remove(image_path)\n",
    "#             os.rmdir('temp_images')\n",
    "            \n",
    "#             print(f\"Successfully extracted {len(paper.questions)} questions.\")\n",
    "#             return paper\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing PDF: {str(e)}\")\n",
    "#             return None\n",
    "\n",
    "#     def display_questions(self):\n",
    "#         \"\"\"Display structured questions.\"\"\"\n",
    "#         print(f\"\\nQuestion Paper ID: {self.paper_id}\")\n",
    "#         print(f\"Total Marks: {self.total_marks}\")\n",
    "#         print(\"\\nQuestions:\")\n",
    "#         print(\"-\" * 50)\n",
    "        \n",
    "#         for q_num, q_data in sorted(self.questions.items(), key=lambda x: int(x[0])):\n",
    "#             print(f\"\\nQuestion {q_num} ({q_data['marks']} marks)\")\n",
    "#             print(f\"{q_data['question']}\")\n",
    "\n",
    "#     def save_to_json(self, filepath):\n",
    "#         \"\"\"Save structured data to JSON.\"\"\"\n",
    "#         data = {\n",
    "#             'paper_id': self.paper_id,\n",
    "#             'total_marks': self.total_marks,\n",
    "#             'questions': self.questions\n",
    "#         }\n",
    "#         with open(filepath, 'w') as f:\n",
    "#             json.dump(data, f, indent=4)\n",
    "\n",
    "#     @classmethod\n",
    "#     def load_from_json(cls, filepath):\n",
    "#         \"\"\"Load structured data from JSON.\"\"\"\n",
    "#         with open(filepath, 'r') as f:\n",
    "#             data = json.load(f)\n",
    "        \n",
    "#         paper = cls(data['paper_id'])\n",
    "#         paper.questions = data['questions']\n",
    "#         paper.total_marks = data['total_marks']\n",
    "#         return paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3c6eddd-0daa-471c-b8a7-0b79318400d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Extracting text from images...\n",
      "Saved question paper to Excel: output/question_paper.xlsx\n",
      "Saved question paper to JSON: output/question_paper.json\n",
      "\n",
      "Question Paper Summary:\n",
      "--------------------------------------------------\n",
      "Total Questions: 7\n",
      "Total Marks: 0\n",
      "\n",
      "Questions:\n",
      "\n",
      "Question 1 (0 marks):\n",
      "hri Vile Parle Kelavani Mandal's 60009210199 DWARKADAS J. SANGHVI COLLEGE OF ENGINEERING (Autonomous College Affiliated to the University of Mumbai) NAAC Accredited with \"A\" Grade (CGPA: 3.18) Department of Computer Science and Engineering (Data Science) 413145 12:30 to 1:30 Term Test-I (AY-2023-2024) Class: Third Year Course Name: Computational Linguistics Total marks: 25 Q. No. QIA\n",
      "\n",
      "Question 2 (0 marks):\n",
      "emester: VI Course Code: DJ19DSC602 Time: 1 hr. Question Calculate the edit distance using Levenshtein distance for the string's \"algorithm\" and \"logarithm,\" considering insertion and deletion costs as 1 and substitution cost as 2.4 Consider the following Training Data <S>I am Jack</S> <S>Jack I am</S> <S>Jack I like</S> <S>Jack I do like</S> <S>do I like Jack</S> Apply Bigram language model on the above data and find what is the most probable next word predicated by the model for the following. <S>do I like ? _ 05 50 05\n",
      "\n",
      "Question 3 (0 marks):\n",
      "emonstrate how two-level morphology can be applied to analyze and generate lexical forms of words using surface forms. Draw diagram for surface level, intermediate level and lexical level for the following words. 1. Foxes 2. Played\n",
      "\n",
      "Question 4 (0 marks):\n",
      "ifferentiate between stemming and lemmatization using suitable example.\n",
      "\n",
      "Question 5 (0 marks):\n",
      "xplain Substitutions and Capture Group in Regular expression. Write the regular expression for the following sentences using substitution and capture group. A) The harder he worked, the harder she worked. B) The happier he became, the happier she became. So 05 05 50 05\n",
      "\n",
      "Question 6 (0 marks):\n",
      "ustify with the suitable example \"Parts of Speech Tagging is disambiguation task\" 05 50\n",
      "\n",
      "Question 7 (0 marks):\n",
      "iscuss with suitable example how the HMM algorithm is trained for Parts of Speech (POS) tagging. What kind of information is required during the training phase? 50 05 PLOT NO. U-15, JVPD SCHEME, BHAKTIVEDANTA SWAMI MARG, VILE PARLE (WEST), MUMBAI 400056. Tel.: 42335000/42335001 Email: info@djsce.ac.in/ admin@djsce.ac.in Website: www.djsce.ac.in\n"
     ]
    }
   ],
   "source": [
    "# # Process question paper\n",
    "# pdf_path = \"qpconvert.pdf\"\n",
    "# question_paper_df = process_question_paper(pdf_path)\n",
    "\n",
    "# # Display the questions in a clean format\n",
    "# print(\"\\nQuestion Paper Summary:\")\n",
    "# print(\"-\" * 50)\n",
    "# print(f\"Total Questions: {len(question_paper_df)}\")\n",
    "# print(f\"Total Marks: {question_paper_df['Marks'].sum()}\")\n",
    "# print(\"\\nQuestions:\")\n",
    "# for _, row in question_paper_df.iterrows():\n",
    "#     print(f\"\\nQuestion {row['Question No.']} ({row['Marks']} marks):\")\n",
    "#     print(row['Question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc9a72-6fd8-4a3f-9aed-6e5e6903c8bf",
   "metadata": {},
   "source": [
    "# _______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23efd797-4810-4768-ad01-ac8dd85d7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_questions(text):\n",
    "    \"\"\"Extract questions, their numbers, and marks.\"\"\"\n",
    "    # First get total marks of paper\n",
    "    total_marks_match = re.search(r'Total marks:\\s*(\\d+)', text)\n",
    "    total_marks = int(total_marks_match.group(1)) if total_marks_match else 0\n",
    "    \n",
    "    # Extract questions\n",
    "    questions = []\n",
    "    \n",
    "    # Pattern to match questions with their numbers and marks\n",
    "    pattern = r'Q(\\d+)([AB]?)\\s*\\.?\\s*([^Q]*)(?=Q\\d+[AB]?|$)'\n",
    "    matches = re.finditer(pattern, text, re.DOTALL)\n",
    "    \n",
    "    for match in matches:\n",
    "        q_num = match.group(1)\n",
    "        q_part = match.group(2)\n",
    "        q_text = match.group(3).strip()\n",
    "        \n",
    "        # Extract marks (looking for patterns like \"05 marks\" or \"Max. Marks 05\")\n",
    "        marks_match = re.search(r'(?:Max\\.\\s*Marks\\s*(\\d+))|(\\d+)\\s*marks?', q_text, re.IGNORECASE)\n",
    "        marks = int(marks_match.group(1) or marks_match.group(2)) if marks_match else 5\n",
    "        \n",
    "        # Clean question text by removing marks information\n",
    "        q_text = re.sub(r'(?:Max\\.\\s*Marks\\s*\\d+)|(?:\\d+\\s*marks?)', '', q_text, re.IGNORECASE)\n",
    "        q_text = q_text.strip()\n",
    "        \n",
    "        questions.append({\n",
    "            'Q. No.': f'Q{q_num}{q_part}',\n",
    "            'Question': q_text,\n",
    "            'Marks': marks\n",
    "        })\n",
    "    \n",
    "    return questions, total_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05653c04-fac7-4c98-bf44-b4e9880ba5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_question_paper_df(text):\n",
    "    \"\"\"Create a clean DataFrame of questions.\"\"\"\n",
    "    # Extract questions and total marks\n",
    "    questions, total_marks = extract_questions(text)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(questions)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Total Marks: {total_marks}\")\n",
    "    print(f\"Number of Questions: {len(df)}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3708707-e5c5-41df-81fc-f671963ef33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(df, filename='question_paper.xlsx'):\n",
    "    \"\"\"Save questions to a formatted Excel file.\"\"\"\n",
    "    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "    df.to_excel(writer, sheet_name='Questions', index=False)\n",
    "    \n",
    "    # Get workbook and worksheet\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Questions']\n",
    "    \n",
    "    # Add formats\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'border': 1,\n",
    "        'bg_color': '#D3D3D3'\n",
    "    })\n",
    "    \n",
    "    cell_format = workbook.add_format({\n",
    "        'text_wrap': True,\n",
    "        'border': 1\n",
    "    })\n",
    "    \n",
    "    # Set column widths\n",
    "    worksheet.set_column('A:A', 10)  # Q. No.\n",
    "    worksheet.set_column('B:B', 60)  # Question\n",
    "    worksheet.set_column('C:C', 10)  # Marks\n",
    "    \n",
    "    # Format headers\n",
    "    for col_num, value in enumerate(df.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_format)\n",
    "    \n",
    "    # Format cells\n",
    "    for row_num in range(len(df)):\n",
    "        for col_num in range(len(df.columns)):\n",
    "            worksheet.write(row_num + 1, col_num, df.iloc[row_num, col_num], cell_format)\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6630a5e-08c1-4513-aa40-6ee2cecb8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question_paper(text):\n",
    "    \"\"\"Main function to process question paper.\"\"\"\n",
    "    # Create DataFrame\n",
    "    df = create_question_paper_df(text)\n",
    "    \n",
    "    # Display DataFrame\n",
    "    print(\"\\nQuestion Paper Structure:\")\n",
    "    display(df)\n",
    "    \n",
    "    # Save to Excel\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e77f8c7-fc25-4a7d-9f4f-713949ccd541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Marks: 25\n",
      "Number of Questions: 5\n",
      "\n",
      "Question Paper Structure:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q. No.</th>\n",
       "      <th>Question</th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2B</td>\n",
       "      <td>Demonstrate how two-level morphology can be ap...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q3A</td>\n",
       "      <td>Differentiate between stemming and lemmatizati...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3B</td>\n",
       "      <td>OR\\nExplain Substitutions and Capture Group in...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4A</td>\n",
       "      <td>Justify with the suitable example \"Parts of Sp...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q4B</td>\n",
       "      <td>Discuss with suitable example how the HMM algo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Q. No.                                           Question  Marks\n",
       "0    Q2B  Demonstrate how two-level morphology can be ap...      5\n",
       "1    Q3A  Differentiate between stemming and lemmatizati...      5\n",
       "2    Q3B  OR\\nExplain Substitutions and Capture Group in...      5\n",
       "3    Q4A  Justify with the suitable example \"Parts of Sp...      5\n",
       "4    Q4B  Discuss with suitable example how the HMM algo...      5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract text from PDF and process\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from PDF using Google Cloud Vision.\"\"\"\n",
    "    # Convert PDF to images\n",
    "    images = convert_from_path(pdf_path)\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    extracted_text = \"\"\n",
    "    \n",
    "    for image in images:\n",
    "        # Save image temporarily\n",
    "        image.save(\"temp.jpg\", \"JPEG\")\n",
    "        \n",
    "        # Extract text\n",
    "        with open(\"temp.jpg\", \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "        image = vision.Image(content=content)\n",
    "        response = client.document_text_detection(image=image)\n",
    "        extracted_text += response.full_text_annotation.text + \"\\n\"\n",
    "        \n",
    "        # Clean up\n",
    "        os.remove(\"temp.jpg\")\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# Process the question paper\n",
    "pdf_path = \"qpconvert.pdf\"\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "df = process_question_paper(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cacd7cd-6486-406a-b2be-06422b608cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Q. No.    5 non-null      object\n",
      " 1   Question  5 non-null      object\n",
      " 2   Marks     5 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 252.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85ff0860-8cb7-4a84-8f6c-f9865e5e8f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Differentiate between stemming and lemmatization using suitable example.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Question'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f93652-842d-4b26-a348-5e55e10ea5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
